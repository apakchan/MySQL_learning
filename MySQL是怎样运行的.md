# MySQL 逻辑架构

## 1. 逻辑架构剖析

### 1.1 服务器处理客户端请求

MySQL 是典型的 C/S 架构，`Client/Server` 架构，服务器端使用的 `mysqld` 服务。

客户端服务器通信实现效果：**客户端进程向服务器进程发送一段文本（SQL 语句），服务器进程处理后再向客户端进程发送一段文本（处理结果）**

<img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220309225631511.png" alt="image-20220309225631511" style="zoom:67%;" />

展开：

<img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220309231354883.png" alt="image-20220309231354883" style="zoom:50%;" />

### 1.2 Connectors

通过 SDK 来访问 MySQL，例如 Native C API、JDBC、PHP 等。

本质上还是在 **TCP 连接**上通过 MySQL 协议跟 MySQL 服务器进行交互。

接下来 **MySQL server** 可以分为如下三层：

### 1.3 第一层：连接层

客户端访问 MySQL 服务器前，首先要建立 TCP 连接

经过三次握手建立连接后，MySQL 服务器对 TCP 传输来的账号密码做身份认证，权限获取。

TCP 连接请求收到后，要分配一个线程处理这个客户端和服务器的交互，每一个连接都从线程池中去获取，省去了创建和销毁线程的开销。

连接层职责是负责认证、管理连接、获取权限信息。

### 1.4 第二层：服务层

主要完成大多数的核心功能，如 SQL 开销，完成缓存查询，SQL 分析优化和优化及部分内置函数的执行。

在该层，服务器会 **解析查询** 并创建相应的内部 **解析树**，并对其优化：如确定查询表的顺序是否利用索引等。

如果是 SELECT 语句，服务器还会查询内部缓存。

- SQL Interface : SQL 接口

  - 接收用户的 SQL 命令，返回用户需要查询的结果。

- Parser : 解析器

  - 对 SQL 语句进行语法分析，语义分析。将 SQL 分解成数据结构，将这个结构传递到后续进行处理，如果分解中出现错误，说明这个 SQL 语句不合理。
  - SQL 命令传递到解析器时会被解析器验证和解析，并为其创建 **语法树**，会**验证该客户端是否具有执行该查询的权限**。

- Optimizer : 查询优化器

  - SQL 在进行语法解析之后，查询之前会使用查询优化器确定 SQL 语句的执行路径，生成一个**执行计划**。
  - 执行计划表明**应该使用哪些索引**进行查询，表之间的连接顺序如何，最后按照计划中的步骤调用存储引擎提供的方法来真正的执行查询，并将查询结果返回给用户。

- Caches & Buffers : 查询缓存组件

  帮助我们提高查询效率，8.0 被废除，主要是因为命中效率低。

### 1.5 第三层：引擎层

有许多种不同的存储引擎，允许开发人员设置自己的存储引擎。

**真正负责了 MySQL 中数据的存储和提取，对物理服务器级别维护的底层数据执行操作**。

8.0 中的存储引擎：

![image-20220309234156094](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220309234156094.png)

### 1.6 存储层

所有的数据，数据库、表的定义，表的每一行的内容，索引，都是存在 **文件系统** 上，以 **文件** 的方式存在，并完成了与存储引擎的交互。

### 1.7 小结

主要就是对 MySQL 进行分层，且细分各层的职责：

首先要先建立连接且做一些权限认证（连接层）、

连接建立好之后就要处理SQL 并且作出适当优化（服务层）、

SQL 解析完后就要真正处理，而这又通过存储引擎来实现（引擎层）、

存储引擎去文件中查找数据最终返回（文件层）。

## 2. SQL 执行流程

### 2.1 MySQL 中的 SQL 执行流程

![image-20220309235457621](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220309235457621.png)

**MySQL 的查询流程**：

1. 查询缓存：Server 如果在查询缓存中发现了这条 SQL，就直接将结果返回给客户端，否则进入解析器阶段。（大多数情况比较鸡肋，因为命中率低，所以MySQL8.0废除）

2. 解析器：首先 MySQL 需要知道你要做什么，因此要对 SQL 语句做解析，分为词法分析与语法分析。

   - 词法分析：识别 SQL 中的字符串分别是什么，代表什么。
   - 语法分析：判断是否满足SQL语法

3. 优化器：确定 SQL 语句的执行路径，是根据**全表检索**，还是根据**索引检索**。

   **一条查询可以有很多种查询方式，最后都返回相同结果，优化器的作用就是找到其中最好的执行计划**。

4. 执行器：首先判断是否具有权限，如果有则调用具体存储引擎，然后调用底层文件系统，完成查询并返回（还要写入缓存中）。

### 2.2 MySQL 查看具体的SQL执行流程

**未命中缓存**：

![image-20220310230836299](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220310230836299.png)

**命中缓存**：

![image-20220310230852632](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220310230852632.png)

## 3. 数据库缓冲池(buffer pool)

`InnoDB` 存储引擎以页为单位来管理存储空间，我们进行增删改查操作都是在访问页面，为了提高效率，**DBMS 会申请占用内存来作为数据缓冲池**，在真正访问页面之前，需要将磁盘上的页缓存到内存中的 `Buffer Pool` 中后才可以访问。

###  3.1 缓冲池 VS 查询缓存

缓冲池和查询缓存是两回事。

#### 缓冲池

**好处**：省去大量磁盘IO开销，消除CPU与磁盘的鸿沟，增加效率。

**缓存原则**：首先，位置决定效率，提供缓冲池就是为了在内存中直接访问数据；其次，频次决定优先级顺序，**优先对使用频次高的数据进行加载**。

**预读特性**：我们使用一些数据，**大概率还会使用它周围的一些数据**，使用预读的机制提前加载，可以减少未来可能的磁盘IO。

#### 查询缓存

查询缓存是将之前的查询结果缓存下来，相当于是key value 键值对，key就是SQL，value 是查询结果。

### 3.3 查看 / 设置缓冲池大小

```sql
show variables like `innodb_buffer_pool_size`
```

```sql
set global innodb_buffer_pool_size = 26835456;
```

缓冲池默认大小128M，可以自己设置。

### 3.4 多个 Buffer Pool 实例

我们可以手动设置多个缓冲池，每个缓冲池大小就是 `innodb_buffer_pool_size` 除以缓冲池实例数。

缓冲池是连续分配的内存。

### 3.5 引申问题

![image-20220310233716010](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220310233716010.png)

有可能出现 **数据不一致问题**

例如我们修改 Buffer Pool 成功，但是没来得及将数据刷入 MySQL 中就宕机了，这样只能获取脏数据了。



# 存储引擎 

## 1. 存储引擎介绍

### 1.1 InnoDB 引擎：具备外键支持功能的事务存储引擎

如果使用 InnoDB ，那么一张表会产生 1 个或者 2 个文件

- `表名.frm` 描述表结构文件
- 如果采用**系统表空间**模式，数据信息和索引信息都存储在 `ibdata1` 中
- 如果采用**独立表空间**存储，还会产生 `表名.ibd` （存储数据信息和索引信息）

MySQL 8.0 不再单独提供 `表名.frm` 而是合并在 `表名.ibd` 文件中

1. MySQL 大于等于 5.5 版本后，默认采用 InnoDB 引擎
2. InnoDB 是 MySQL 的默认事务引擎
3. 除了增加查询外，还要更新和删除操作，那么优先使用 InnoDB 存储引擎
4. InnoDB 是 **为了处理巨大数据量的最大性能设计**
5. 与 MyISAM 相比，**InnoDB** 的写效率差一些，并且占据更多的内存空间以保存数据和索引。
6. MyISAM 只缓存索引，不缓存真实数据，InnoDB 不但缓存索引还要缓存真实数据，**对内存要求高**

### 1.2 MyISAM 引擎：主要的非事务处理存储引擎

如果使用 MyISAM 引擎，会产生 3 个文件：

- MySQL 5.7 中：`表名.frm` 描述表结构文件
  MySQL 8.0 中：`表名.xxx.sdi`：描述表结构文件
- `表名.MYD`(`MyData`) ：数据信息文件，存储数据信息。
- `表名.MYI`（`MyIndex`）：存放索引信息文件

1. 优点是访问速度快，对事务完整性没有要求或者以 SELECT、INSERT 为主的应用
2. 针对数据统计有额外的常数存储，count(*) 的效率很高
3. 应用于只读或者以读为主的业务。

### 1.3 Archive引擎：用于数据存档

- `archive` 是归档的意思，仅支持`插入`和`查询` 两种功能。
- MySQL 5.5 版本后才支持索引功能。
- 拥有很好的压缩机制，使用 `Zlib` 压缩库
- 创建 `ARCHIVE` 表时，存储引擎会创建名称以表名开头的文件。数据文件扩展名为 `.ARZ`
- 采用行级锁
- 适合 **日志表和数据采集（档案）** 类应用；**适合存储大量的独立的作为历史记录的数据**。具有很高速度。

### 1.4 CSV 引擎：存储数据时，以逗号分隔各个数据项

- CSV 引擎可以将 **普通的CSV文件作为MySQL的表来处理**，但不支持索引。
- CSV 引擎可以作为一种数据交换的格式

### 1.5 Memory 引擎：置于内存的表

采用的逻辑介质是内存，相应速度快，但是当 MySQL 崩溃时数据会丢失

**特征**：

- 比 MyISAM 快一个数量级
- 表的大小受限制
- 缺点：数据易失，生命周期短。

**场景**：

1. 目标数据小，访问频繁
2. 数据临时，而且是必须立即可用
3. 如果数据突然丢失关系也不大



## 2. MyISAM 和 InnoDB

| 对比项         | MyISAM                                                 | InnoDB                                                       |
| -------------- | ------------------------------------------------------ | ------------------------------------------------------------ |
| 外键           | 不支持                                                 | 支持                                                         |
| 事务           | 不支持                                                 | 支持                                                         |
| 行表锁         | 表锁，操作一条记录也会锁住整个表<br />不支持高并发操作 | 行锁，操作时只锁住某一行，不影响其他行<br />适合高并发操作   |
| 缓存           | 只缓存索引，不缓存真实值                               | 不仅缓存索引还要缓存真实值<br />对内存要求高，内存大小对性能有决定性的影响 |
| 自带系统表使用 | No                                                     | Yes                                                          |
| 关注点         | 性能：节省资源、消耗少、简单业务                       | 事务：并发写、事务、更大资源                                 |
| 默认安装       | Yes                                                    | Yes                                                          |
| 默认使用       | No                                                     | Yes                                                          |



# 索引

## 1. 为什么使用索引及其优缺点

是存储引擎中快速找到数据记录的一种数据结构，好比一本书的目录部分，通过目录找到对应文章的页码，可以快速定位到需要的文章。

![image-20220311152816556](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220311152816556.png)

**索引的本质：索引是数据结构，简单理解为 "排好序的快速查找数据结构"，满足特定查找算法**

### 优点

1. 提高数据检索效率，降低数据库 IO 成本
2. 通过创建唯一索引，保证数据库中每一行的唯一性
3. 可以加速表和表之间的连接
4. 显著减少查询中分组和排序时间。

### 缺点

1. 创建和维护索引要耗费时间
2. 索引要占据磁盘空间，如果有大量的索引，索引文件可能比数据文件更快达到最大文件尺寸。
3. 降低更新表的数据

## 2. InnoDB 中的索引方案

![image-20220311160015196](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220311160015196.png)

InnoDB 的 B+ 树结构

- B+树叶节点有双向的指针
- B+树多路
- B+树非叶子节点的数据都冗余了一份在叶子节点上
- 非叶子结点不存储 data，只存储索引（冗余）

![image-20220311160804069](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220311160804069.png)

## 3. 常见索引概念

索引按照物理实现方式可以分为两种：**聚簇索引和非聚簇索引**。非聚簇索引也被称为二级索引或者辅助索引。

### 3.1 聚簇索引

上图的索引就是一个聚簇索引。

聚簇索引是一种**数据存储方式**（所有的用户记录都存储在叶子节点上），**索引即数据，数据即索引**。

> 术语 "聚簇" 表示数据行和相邻的键值聚簇的存储在一起。

**特点**：

1. 使用主键值的大小进行记录和页排序，包括三个方面的含义：
   - `页内` 的记录是按照主键的大小顺序排成一个 `单向链表`
   - 各个存放 `用户记录的页` 也是根据页中用户记录的主键大小顺序排成一个 `双向链表`
   - 同一层次中的页也是根据页中目录项记录的主键大小顺序排成一个 `双向链表`。

2. B+ 数的 `叶子节点` 存储的是完整的用户记录

聚簇索引不需要我们用显示的 Index 语句创建，InnoDB 存储引擎会自动为我们创建聚簇索引。

**优点**：

- 数据访问更快，因为数据和索引都保存在 B+ 树中。
- 对于主键的 `排序查找` 和 `范围查找` 速度非常快
- 按照聚簇索引排序的顺序查询一定范围的数据时，速度非常快，因为数据紧密相连，所以节省了大量 IO

**缺点**：

- `插入速度严重依赖于插入顺序`，按主键插入的顺序是最快的方式，否则出现页分裂，严重影响性能。
- `更新主键的代价很高`，对于 InnoDB 表，我们一般**定义主键不可更新**。
- `二级索引访问需要两次索引查找`，第一次找到主键值，第二次根据主键值找到行数据

**限制**：

- 对于 MySQL 数据库目前只有 InnoDB 支持聚簇索引，MyISAM 不支持。
- 由于数据物理存储排序方式只有一种，所以**每个表只能有一个聚簇索引**，一般情况下就是主键。
- 如果没有定义主键，InnoDB会选择 `非空的唯一索引` 代替，如果没有这种索引，InnoDB会隐式的定义一个主键来作为聚簇索引。
- InnoDB的主键尽量选择选用**有序的顺序ID**，不建议用无序ID。

### 3.2 二级索引(辅助索引、非聚簇索引)

我们可以基于其他列作为索引去构建一棵 B+ 树。

![image-20220312141708353](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220312141708353.png)

节点存储的不是具体的数据，而是对应行的主键值。查到主键值之后需要再 **回表** 查找具体的行数据。

> 回表
>
> 在非聚簇索引中查到主键值后，需要再回表查找完整的用户记录。

**小结**：聚簇索引和非聚簇索引原理不同，在使用上也有一些区别

1. 聚簇索引的 `叶节点` 存储的是 `数据记录`，非聚簇索引的叶节点存储的是 `数据位置`，非聚簇索引不会影响数据表的物理存储顺序。
2. 一个表只能有一个聚簇索引，但是可以有多个非聚簇索引。
3. 使用聚簇索引数据的**查询效率高**，但是对于数据的插入，删除，更新等操作，效率会比非聚簇索引低。

### 3.3 联合索引

属于非聚簇索引，基于多个字段作为索引。

## 4. InnoDB的 B+ 树索引的注意事项

### 1. 根页面位置万年不动

![image-20220312152045330](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220312152045330.png)

根节点的位置始终不动，但是要分裂页面。

### 2. 内节点中目录项记录的唯一性

如果内节点（非叶节点）的索引数据有重复，那么为了确保目录项的唯一性（不包含页号），需要带上主键的值。

![image-20220312152939748](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220312152939748.png)

### 3. 一个页面最少存储 2 条记录

如果一页只能存储一条记录，那么就是一个链表的形式。

## 5. MyISAM 索引的原理

MyISAM 是索引与数据分开。

<img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220312153444590.png" alt="image-20220312153444590" style="zoom:67%;" />

**MyISAM 索引文件仅仅保存数据记录的地址**。可以理解为非聚簇索引文件。

### 与 InnoDB 对比

**MyISAM 的索引方式都是"非聚簇"的；InnoDB 只包含 1 个聚簇索引不同。**

- 在 InnoDB 存储引擎中，我们只需要根据主键值对 `聚簇索引` 进行一次查找就能找到记录，而 MyISAM 需要回表。
- InnoDB 的数据文件本身就是索引文件， MyISAM **索引文件和数据文件分离**，索引文件仅包含地址。
- InnoDB 的非聚簇索引未见节点存放主键值，而MyISAM存放**物理地址**。
- MyISAM 回表速度很快，而 InnoDB 是根据主键去聚簇索引中找记录，速度不慢，但是不如直接用**物理地址**。

- InnoDB 需要表**必须有主键**，而MyISAM 可有可无。

## 6. 索引的代价

在空间和时间都会有消耗。

- **空间的代价**

  每建立一个索引都要为它建立一颗B+ 树，每一棵 B+ 数的每一个节点都是一个数据页，一个页会占用 16KB 的存储空间，一颗很大的 B+ 树会占据很大一片存储空间。

- **时间的代价**

  每次对表中数据进行增删改操作时，都要去修改各个 B+ 树索引，不论是叶子结点，还是非叶子节点，随着增加的记录越来越多，那么要也要调整它们的空间结构，这都是要耗费时间的。

## 7. MySQL 数据结构选择的合理性

磁盘 IO 的操作次数对索引的使用效率至关重要。

### 7.1 全表遍历

效率最低，不解释。

### 7.2 Hash结构

Hash 本身是一个散列函数，可以大幅提高检索数据的效率，时间复杂度为O(1)

从效率来看 Hash 的效率大于 B+ 树的效率，但是为什么采用树形而不是用Hash呢？

原因1： Hash 索引只能满足 =，!=，和 IN 查询，如果进行范围查询，时间复杂度退化为 O(n)，而树形仍能保持O(log2n)的高效

原因2：Hash还有缺陷，数据的存储是无序的，如果使用 Order By，Hash索引还要进行排序。

原因3：对于联合索引，Hash值是将联合索引缝合后一起计算的，无法对一个或者几个键进行查询。

原因4：如果索引重复的值特别多，那么就会存在 Hash 冲突，效率降低。

**另外**：

InnoDB本身不支持 Hash 索引，但是提供 **自适应的 Hash 索引**，如果某一个数据经常被访问，当满足一定条件时，就会将这个页的地址存放到 Hash 表中，这样下次查询时，就会直接找到这个页面所在的位置，这样让 B+ 数也具备了 Hash 索引的优点。

<img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220312161239966.png" alt="image-20220312161239966" style="zoom:67%;" />

### 7.3 二叉搜索树

时间复杂度为 `O(logn)` 如果按照单调性唯一的顺序去插入数据，那么二叉树就会退化成为链表，时间复杂度降级为O(n)

### 7.4 AVL树

可以严格保证平衡，但是如果插入的数很多，那么AVL树**层数就会很大**，而我们每访问一次节点就需要 IO，效率不高。

![image-20220312161645846](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220312161645846.png)

那么我们如果提高叉的数量，效率就会提高。

### 7.5 B树

多路平衡查找树，它的高度远小于平衡二叉树的高度。

![image-20220312162053553](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220312162053553.png)

数据由 B 树生成：叶子结点和非叶子结点都可能存放记录

![image-20220312162429283](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220312162429283.png)

### 7.6 B+树

<img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220311160804069.png" alt="image-20220311160804069" style="zoom:67%;" />

与 B 树差异：

- 孩子数量等于关键字数量，而 B 数孩子数量等于关键字数量 + 1
- 非叶子结点的关键字也会存在叶子结点中（叶节点冗余一份），并且是子节点关键字最大（或最小）
- 非叶子结点仅用于索引，不保存数据记录，跟记录有关的信息都在叶子结点中，B树中，**非叶子结点即保存索引也保存数据记录**。
- 所有关键字都在叶子结点出现，叶子结点构成有序链表，而且叶节点本身按照关键字大小从小到大顺序连接。

### 思考

**B+树的存储能力如何？为何说一般查找行记录，最多只需1-3次IO**

> 页大小为16KB，一般主键类型为INT或者BIGINT(8byte)，指针类型也为8byte，一页大概存储16KB/(8 + 8 byte) = 1K个键值。
>
> 那么一个深度为3的 B+树 索引可以维护 10^3^ * 10^3^ * 10^3^ = 10亿条记录
>
> 实际情况不可能每个节点都填满，因此在数据库中， **B+ 树的高度一般在 2- 4 层**，MySQL的 InnoDB 引擎在设计时将根节点常驻内存，那么MySQL查找某一键值的行记录最多只需要1 - 3次IO

# InnoDB 数据存储结构

## 1. 数据库的存储结构：页

索引结构和数据信息都是保存在文件中，确切说是**保存在页结构**中。

索引是在存储引擎中实现，MySQL 服务器上的 **存储引擎** 负责对表中数据的读取和写入工作。不同**存储引擎**中的存放格式一般不同。

### 1.1 磁盘与内存交互基本单位：页

InnoDB 页大小默认为 16KB

页是磁盘和内存交互的基本单位，也就是一次最少从磁盘中读取 16KB 的内容到内存中，**在数据库中，不论读一行，还是读多行，都是将这些行所在的页进行加载。也就是说，数据库管理存储空间的基本单位就是页，数据库 IO 的最小单位是页。**

> 一页中存储多个 行记录。
>
> 记录按照行存储，但是数据库的读取并不以行为单位，否则一次读取只能处理一行数据，效率会非常低。

![image-20220313155238990](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220313155238990.png)

### 1.2 页结构概述

页 a, b, c, d... 这些页可以 **不在物理结构上相连**，只要通过 **双向链表** 关联即可，每个数据页中的记录会按照主键值从小到大的顺序组成一个 **单向链表**，每个数据页都会为存储在它里面的记录生成一个 **页目录**，通过主键查找某记录时可以在页目录中 **使用二分** 快速找到对应的槽，再遍历该槽对应分组中的记录即可快速找到指定的记录。

### 1.3 页的上层结构

在数据库中，还存在区、段、表空间的概念。

<img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220313160027500.png" alt="image-20220313160027500" style="zoom:67%;" />

InnoDB 中一个区分配64个连续的页，一个区大小为 64 * 16KB = 1MB

段由一个或多个区组成，区在文件系统中是一个连续分配的空间，段中不要求区相邻。**段是数据库中的分配单位，不同类型的数据库对象以不同的段形式存储**。

表空间是一个逻辑容器，表空间存储段，一个表空间可以有多个段，一个段只能有一个表空间。数据库由一个或者多个表空间组成，表空间从管理上可以分为 `系统表空间`、`用户表空间`、`撤销表空间`、`临时表空间` 等。

## 2. 页的内存结构

页如果按类型分，常见的有 **数据页（保存 B+ 树节点）、系统页、Undo页和事务数据页**等，数据页是我们最常使用的页。

<img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220313161735504.png" alt="image-20220313161735504" style="zoom:67%;" />

<img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220313161816102.png" alt="image-20220313161816102" style="zoom:67%;" />

### 2.1 文件头和文件尾

#### 文件头 38byte

描述各种页的通用信息，例如页编号，checkSum，上一页下一页等

<img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220313162238869.png" alt="image-20220313162238869" style="zoom:67%;" />

#### 文件尾 8byte

前 4 个字节代表页 checkSum

后 4 个字节代表页面最后修改时对应的日志序列位置（LSN）：
也是为了检验页的完整性，如果首部和尾部的 LSN 值校验不成功，就说明同步过程出现了问题。

### 2.2 用户记录，最大最小记录，空闲空间

这个部分是记录部分，页的主要作用是存储记录，所以最大和最小记录和用户记录占了页结构的主要空间。

![image-20220313163922926](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220313163922926.png)

#### 空闲空间 (不确定)

我们每向页中插入一条记录，都会从空闲空间申请一个记录大小的空间划分到 User Records 部分，当空闲空间被用户记录替代掉之后，也就意味着这个页使用完了，如果还要插入新的记录，就要去申请新的页了。

#### 用户记录 (不确定)

记录头信息：

![image-20220313165618543](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220313165618543.png)

#### 最大和最小记录 26byte

记录通过比较主键大小来比较大小

### 2.3 页目录，页头

#### 页目录 (不确定)

通过页目录来实现二分查找，效率更高。

#### 页头 56byte

## 3. InnoDB 行格式

### COMPACY 行格式

从 MySQL5.1 开始，默认行格式就是 COMPACT 格式

<img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220313172325866.png" alt="image-20220313172325866" style="zoom:67%;" />

#### 变长字段长度列表

MySQL 支持一些变长的数据类型，例如 Varchar、VarBinary、Text、Blob类型

**在Compact行格式中，把所有变长字段的真实数据占用的字节长度都存放在记录的开头部位，从而形成一个变长字段长度列表。**

#### Null 值列表

会把可以为 NULL 的列统一管理，存在一个标记为 NULL 值列表中，如果表中没有允许存储 NULL 的列，则 NULL 值列表也就不存在了。

1. 二进制位的值为1，代表该列的值为 NULL
2. 二进制位的值为0，代表该列的值不为 NULL

![image-20220313173148552](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220313173148552.png)

#### 记录头信息

![image-20220313165618543](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220313165618543.png)

### Dynamic 和 Compressed 行格式

#### 行溢出

如果一个页存放不了一条记录，这种情况成为行溢出，例如 Varchar 类型的字符设置的长度过长（大于 65535）

#### Dynamic 和 Compressed 行格式

MySQL8.0 中，默认行格式就是 Dynamic，Dynamic、Compressed行格式与Compact行格式挺像，不过在处理行溢出时有分歧：

- Compressed 和 Dynamic 对于存放在 Blob 的数据使用了完全的行溢出方式。
  如图：在数据页中只存放 20 个字节的指针（溢出页的地址），实际的数据都存放在 Off Page(溢出页)中

  <img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220313175055294.png" alt="image-20220313175055294" style="zoom:50%;" />

- Compact 和 Redundant 两种格式会在记录的真实数据处存储一部分数据（存放768个前缀字节）

Compressed 行记录格式的另一个功能就是，存储在其中的行数据会以 `zlib` 的算法进行压缩，因此存大长度类型的数据可以进行非常有效的存储。

# 索引的创建与设计原则

## 1. 索引的声明和使用

### 1.1 索引的分类

包括**普通索引、唯一性索引、全文索引、单列索引、多列索引**和**空间索引**等。

- 从 `功能逻辑` 上来说，索引主要分为四种：**普通索引、唯一索引、主键索引、全文索引。**
- 按照 `物理实现` 方式，索引分为 **聚簇索引** 和 **非聚簇索引**。
- 按照 `作用字段个数` 进行划分，分为 **单列索引** 和 **联合索引** 。

#### 普通索引

没有任何限制条件，只是用于提高查询效率。可以创建在 **任何数据类型** 中，其值是否唯一和非空，要由字段本身的完整性约束条件决定。            

#### 唯一性索引 

使用 `UNIQUE` 参数可以设置为唯一性索引，限制该索引的值必须唯一，但允许有空值。一张表 **可以有多个** 唯一索引。

#### 主键索引

特殊的唯一索引，在**唯一索引**的基础上添加了**不为空**的约束，一张表**最多有一个**主键索引。

#### 单列索引

在单个字段上创建索引，单列索引可以是普通索引、唯一性索引、全文索引。只要保证索引只对应一个文字即可。
一个表可以**有多个**单列索引。

#### 多列索引

**多个字段组合** 上创建一个索引，使用组合索引应该遵循 **最左前缀原则**。

#### 全文索引

是 `搜索引擎` 的一种技术，只为 `CHAR`、`VARCHAR` 和 `TEXT` 列创建索引。

#### 空间索引

只有 MyISAM 支持空间检索，而且索引的字段不能为空值。

空间索引 只能建立在空间类型上，这样可以提高系统获取空间数据的效率。

### 1.2 创建索引

#### 创建表时创建索引

**隐式创建** 索引，声明有主键约束，唯一性约束，外键约束的字段上，自动添加相关索引。

```sql
CREATE TABLE dept (
	dept_id INT PRIMARY KEY AUTO_INCREMENT, # 主键索引
	dept_name VARCHAR(20)
);

CREATE TABLE emp (
	emp_id INT PRIMARY KEY AUTO_INCREMENT,
    emp_name VARCHAR(20) UNIQUE, # 唯一索引
    dept_id INT,
    CONSTRAINT emp_dept_id_fk FOREIGN KEY(dept_id) REFRENCES dept(dept_id); # 外键索引
)
```

**显示创建**：

```sql
CREATE TABLE `table_name` [col_name data_type]
[UNIQUE | FULLTEXT | SPATIAL] [INDEX | KEY] [index_name] (col_name [length]) [ASC | DESC]
```

- `UNIQUE | FULLTEXT | SPATIAL` 为可选参数，分别表示**唯一索引**、**全文索引**和**空间索引**。
- `INDEX` 和 `KEY` 同义词，用来指定创建索引。
- `index_name` 索引名称
- `col_name` 需要创建索引的字段列，要从数据表中定义的多个列选择。
- `length` 表示索引长度，只有字符串类型字段才能指定索引长度。
- `ASC、DESC` 指定升序或者降序的索引值存储。

```sql
CREATE TABLE book (
	book_id INT,
    book_name VARCHAR(100),
    `authors` VARCHAR(100),
    info VARCHAR(100),
    `comment` VARCHAR(100),
    year_publication YEAR,
    # 声明索引
    INDEX idx_bname(book_name),
    UNIQUE INDEX uk_idx_cmt(`comment`);
);

SHOW INDEX FROM `table_name`;
```

#### 在已经存在的表上添加索引

**使用 ALTER TABLE 语句创建索引**

```sql
ALTER TABLE `table_name`
ADD [UNIQUE | FULLTEXT | SPATIAL] [INDEX | KEY] [index_name] (col_name [length], ...) [ASC | DESC]
```

例子：

```sql
CREATE TABLE book (
	book_id INT PRIMARY KEY,
    book_name VARCHAR(100),
    `authors` VARCHAR(100),
    info VARCHAR(100),
    `comment` VARCHAR(100),
    year_publication YEAR
);

ALTER TABLE book
ADD INDEX idx_cmt(`comment`);
```

**使用 CREATE INDEX 方式创建索引**

```sql
CREATE 
[UNIQUE | FULLTEXT | SPATIAL] [INDEX | KEY] [index_name]
ON
`table_name`(`table_col`[length]) [ASC | DESC]
```

举例：

```sql
CREATE TABLE book (
	book_id INT PRIMARY KEY,
    book_name VARCHAR(100),
    `authors` VARCHAR(100),
    info VARCHAR(100),
    `comment` VARCHAR(100),
    year_publication YEAR
);

CREATE INDEX idx_cmt ON book(`comment`);
```

### 1.3 删除索引

```sql
ALTER TABLE `tableName`
DROP INDEX `indexName`;
```

```sql
DROP INDEX `indexName` ON `tableName`
```

## 2. MySQL8.0 索引新特性

### 2.1 降序索引

虽然 MySQL4 支持降序索引语法，但实际上 DESC 定义是被忽略的，直到 MySQL8.0 才开始真正支持。

**MySQL8.0 之前创建的仍然是升序索引，使用时进行反向扫描，这大大降低了数据库的效率。**

```sql
CREATE TABLE ts1 (a INT, b INT, INDEX idx_a_b(a ASC, b DESC));

select * from ts1 order by a, b, DESC LIMIT 5;
```



### 2.2 隐藏索引

MySQL5.7 之前，只能通过显示方式删除索引，如果发现删除索引后出现错误，只能通过显式创建索引将删除的索引创建回来。

MySQL8.0 开始支持 `隐藏索引`，将待删除的索引设置为隐藏索引，使查询优化器不再使用这个索引，确认将索引设置为隐藏索引后系统不受任何响应，就可以彻底删除索引。又称 **软删除**。

> 索引默认可见，使用 CREATE TABLE，CREATE INDEX 或者 ALTER TABLE 等语句可以通过 `VISIBLE` 或者 `INVISIBLE` 设置索引的可见性

```sql
CREATE TABLE book (
	book_id INT,
	book_name VARCHAR(100),
    `authors` VARCHAR(100),
    `comment` VARCHAR(100),
    year_publication, YEAR,
    INDEX idx_cmt(`comment`) INVISIBLE;
);
```

修改索引的可见性

```sql
CREATE INDEX idx_year_pub ON book(year_publication);

ALTER TABLE book 
ALTER INDEX idx_year_pub invisible;
```

## 3. 索引的设计原则

### 3.1 适合创建索引的场景

- **字段的数值有唯一性限制**

  添加唯一索引或者主键索引。

  > 业务上具有唯一特性的字段，即使是组合字段，也必须建成唯一索引。

- **频繁作为 WHERE 查询条件的字段**

- **经常要 GROUP BY 或者 ORDER BY 的列**

  如果既要 GROUP BY 又要 ORDER BY，应该建立联合索引，且符合最左前缀原则

- **UPDATE、DELETE 的 WHERE 条件列 **

- **DISTINCT 字段需要创建索引**

- **多表 JOIN 连接时，创建索引注意事项**

  - 连接表的数量尽量不要超过三张，因为每增加一张表就相当于增加了一次嵌套循环，数量级增长很快，严重影响查询效率
  - 对 WHERE 条件创建索引
  - 最后对用于连接的字段创建索引

- **使用列的类型小的创建索引**

  这里说的 类型大小 是指该类型表示的数据范围的大小。

  - 数据类型越小，比较操作就越快
  - 数据类型越小，索引占用的空间越少，一个数据页可以放下更多的记录。

- **使用字符串前缀创建索引**

  和前一个原因类似，如果没有必要比较完整的字符串，那么就选择尽量短的前缀进行比较

- **散列性高的列适合作为索引**

  列的基数表示某一列中的不重复的个数，列的基数越高，列的值越分散。

- **使用最频繁的列放到联合索引的左侧**

- **在多个字段都要创建索引的情况下，联合索引优于单值索引**

### 3.2 不适合创建索引的场景

- **WHERE 中用不到的字段，不用设置索引**

- **数据量小的表，不用设置索引**

- **有大量重复数据的列上不要建立索引**

- **避免对经常更新的表创建过多的索引**

  频繁更新的字段不一定要创建索引；创建索引虽然提高了查询速度，但是会降低更新表的速度。

- **不建议用无序的值作为索引**、

  插入时会造成页分裂，维护会耗费更多的资源。

- **删除不再使用或者很少使用的索引**

- **不要定义冗余或者重复的索引**

  - **冗余索引**：例如索引 `idx_name_birthday_phone_number(name(10), phone_number)`
    	与索引 `idx_name(name(10))`，这里的单列索引就是没有必要的

  - **重复索引**：`uk_idx_c1 (col1)` 与 `idx_c1 (col1)` 是重复的索引

# 性能分析工具的使用

## 1. 优化步骤

<img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220319154819519.png" alt="image-20220319154819519" style="zoom:40%;" />

<img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220319154836519.png" alt="image-20220319154836519" style="zoom:40%;" />

<img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220319154931468.png" alt="image-20220319154931468" style="zoom:40%;" />

## 2. 慢查询工具的使用



# 十章. 单表访问方法

MySQL 会有一个称为优化器的模块。MySQL Server 在对一条查询语句进行语法解析后，就会将其交给优化器来优化，优化的结果就是生成一个执行计划，这个计划表明应该使用哪些索引进行查询、表之间的连接顺序如何等等，最后会按照执行计划中的步骤调用存储引擎提供的接口来真正执行查询，并将查询结果返回给客户端。

为了方便演示首先创建一张表：

```mysql
create table single_table (
	id int not null AUTO_INCREMENT,
	key1 varchar(100),
	key2 int,
	key3 VARCHAR(100),
	key_part1 varchar(100),
	key_part2 varchar(100),
	key_part3 varchar(100),
	common_field varchar(100),
	primary key(id),
	key idx_key1 (key1),
	unique key uk_key2 (key2),
	key idx_key3 (key3),
	key idx_key_part (key_part1, key_part2, key_part3)
) Engine=InnoDB charset=utf8;
```

我们为这个 `single_table` 建立了 1 个聚簇索引和 4 个二级索引：

- id 主键列的聚簇索引
- key1 建立的 `idx_key1` 二级索引
- key2 建立的 `uk_key2` 唯一二级索引
- key3 建立的 `idx_key3` 二级索引
- 为 `key_part1, key_part2, key_part3` 建立的 `idx_key_part` 联合二级索引。

## 10.1 访问方法的概念

MySQL 执行查询语句的方式就称为访问方法，同一个查询语句可以采取多种不同的访问方式来执行，虽然最后的查询结果相同，但是不同的执行方式花费时间成本不同。

下面介绍各种访问方法的具体内容：

## 10.2 `const`

有时可以通过主键列来定位一条记录，例如下面这个查询：

```mysql
select * from single_table where id = 1436;
```

MySQL 会直接利用主键值在聚簇索引中定位对应的用户记录

我们根据**唯一二级索引**来定位一条记录也是很快的，例如这条查询：

```mysql
select * from single_table where key2 = 3811;
```

这个查询的执行分为如下两步：

1. 在 `uk_key2` 对应的 B+ 树索引中，根据 key2 与常数的等值比较条件定位到一条二级索引记录
2. 根据该记录的 id 到聚簇索引中获取完整的用户记录。

MySQL 的设计者认为，通过主键或者唯一二级索引列与常数的等值比较来定位一条记录是很快的，所以它们把这种**通过主键或者唯一二级索引列来定位一条记录**的访问方法定义为 `const`。

不过这种 `const` 访问方法只能在主键列或者唯一二级索引列与一个常数进行等值比较才有效，如果主键或者唯一二级索引的索引列由多个列组成，只有在索引列中的每一个列都和常数进行等值比较这个 `const` 访问方法才有效。

对于唯一二级索引来说，查询列为 null 值时，情况较为特殊，因为唯一二级索引不限制 null 值的数量，所以上述语句可能访问到多条记录，也就是说下面这个语句不可以用 `const` 访问方法执行。

```mysql
select * from single_table where key2 is null;
```

## 10.3 ref

有时我们要将某个普通的二级索引列与常数进行比较：

```sql
select * from single_table where key1='abc';
```

对于这个查询我们可以使用 `idx_key1` 来执行，此时对应的扫描区间就是 `['abc', 'abc']`，这是一个单点扫描空间，我们可以定位到 `key1='abc'` 的第一条记录，然后沿着记录所在的单向链表向后扫描，直到某条记录不符合 `key1='abc'` 条件为止。

由于查询列是 * 所以需要根据二级索引的 id 值执行回表操作，到聚簇索引中获取到完整的用户记录然后发送给科幻。

<img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220514142951479.png" alt="image-20220514142951479" style="zoom:50%;" />

MySQL 的设计者将这种 "搜索条件为二级索引列与常数进行等值比较，形成的扫描区间为单点扫描区间，采用二级索引来执行查询" 的访问方法称为 `ref`。如果该扫描区间的记录较少，则回表操作的代价还是比较低的。

> 采用二级索引来执行查询时，其实每获取到一条二级索引记录就会立刻对其执行回表。

注意下面两种情况：

- 二级索引列运行存储 null 时，无论是普通的二级索引，还是唯一二级索引，它们的索引列不限制 null 的数量，所以执行包括 `key is null` 形式的搜索条件的查询时，最多只能使用 ref 访问方法，不能使用 `const` 访问方法。

- 对于索引列包含多个列的二级索引，只要最左边连续的列是与常数进行等值比较，就可以采用 ref 访问方法，例如一下几个查询都可以采用 ref 访问方法：

  ```sql
  select * form single_table where key_part1 = 'hello';
  
  select * form single_table where key_part1 = 'hello' and key_part2 = 'world';
  
  select * form single_table where key_part1 = 'hello' and key_part2 = 'world' and key_part3 = '!';
  ```

  如果索引列中最左连续的列不是等值比较的话，它的访问方法就不是 ref 了，例如下面这句：

  ```sql
  # 事实上这句访问方法是 range
  select * form single_table where key_part1 = 'hello' and key_part2 > 'world';
  ```

## 10.4 `ref_or_null`

有时我们不仅想找出某个二级索引列的值等于某个常数的记录，还想把该列中值为 null 的记录找出来，例如下面这个查询：

```sql
select * from single_table where key1='abc' or key1 is null; 
```

当使用二级索引而不是全表扫描的方式执行该查询时，对应的扫描区间就是 `[null, null]` 以及 `['abc', 'abc']`，此时执行这种类型的查询所使用的访问方法就是 `ref_or_null`。

![image-20220514144559080](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220514144559080.png)

`ref_or_null` 访问方法只是比 ref 访问方法多扫描了一些值为 `null` 的二级索引记录。

> 值为 null 的记录会被放在索引的最左边。

## 10.5 range

在对索引列与某一个常数执行等值比较才会执行前面提过的访问方法 `const、ref、ref_or_null`，但是有时我们面对的搜索条件很复杂，例如：

```sql
select * from single_table where key2 in (1438, 6328) or (key2 >= 38 and key2 <= 79);
```

如果使用 `idx_key2` 执行该查询，那么对应的扫描区间就是 `[1438, 1438]、[6328, 6328]、[38, 79]`。

MySQL 的设计者把 "使用索引执行查询时，对应的扫描区间为若干个单点扫描区间或者范围扫描区间" 的访问方法称为 `range`。（不包括一个单点扫描或者范围为 `[-∞, +∞]`）

## 10.6 index

来看下面这个查询：

```sql
select key_part1, key_part2, key_part3 
from single_table 
where key_part2='abc';
```

由于 `key_part2` 不是联合索引 `idx_key_part` 索引列中最左边的列，所以无法形成合适的范围区间来减少需要扫描的记录数量，从而无法使用 ref 或者 range 去执行这个语句，这个查询符合下面两个条件：

- 它的查询列表只有 `key_part1, key_part2, key_part3`，而索引 `idx_key_part` 正好包含这 3 个列。
- 搜索条件中只有 `key_part2` 列，这个列也包含在索引 `idx_key_part` 中。

也就是说我们直接遍历 `idx_key_part` 索引的所有二级索引记录，针对获取到的每一条二级索引记录，都判断 `key_part2='abc'` 是否成立，如果成立就从中读取出 `key_part1, key_part2, key_part3 ` 这三个列的值，并将它们发送到客户端。显然这种使用 `idx_key_part` 索引执行上述查询的情况下，对应的扫描区间是 `[-∞, +∞]`.

由于二级索引记录比聚簇索引小得多，这个过程不需要回表，索引直接扫描全部二级索引比扫描全部聚簇索引的成本小得多。

另外，当全表扫描对使用 `InnoDB` 存储引擎的表执行查询时，如果添加了 `Order by 主键` 的语句，那么该语句执行时也会被人认为使用的是 `index` 访问方法，如下面这个查询：

```sql
select * from single_table order by id;
```

## 10.7 all

就是全表扫描，直接扫描全部的聚簇索引记录。

## 10.8 注意事项

### 10.8.1 重温二级索引+回表

使用索引时，一般情况下只会为单个索引生成扫描区间，比如下面这条查询：

```sql
select * 
from single_table 
where key1 = 'abc' and key2 > 1000;
```

查询优化器会识别这个查询中的两个搜索条件：

- `key1 = 'abc'` 
- `key2 > 1000`

如果使用 `idx_key1` 执行查询，查询方法就是 ref，如果使用 `idx_key2` 执行查询，查询方法就是 range。

优化器最终会采用成本更小的那个扫描区间对应的索引执行查询。

一般来说等值查找比范围查找需要扫描的记录数更少。这里假设使用 `idx_key1` 进行查询，则步骤为：

- 通过 `idx_key1` 对应的 B+ 数定位到扫描区间 `['abc', 'abc']` 中的第一条二级索引记录。
- 根据从上一步得到的二级索引记录的主键进行回表扫描，得到完整的用户记录，再检测是否符合 `key2 > 1000` 这个条件，满足则发送到客户端。

> 每次从二级索引中读取到一条记录后，会根据该记录的主键执行回表，而二级索引记录的主键值是无序的，所以每次执行回表就相当于随机读取一个聚簇索引页面，这些随机 IO 带来的性能开销较大。MySQL 的设计者就提出一个名为 `Disk-Sweep Multi-Range Read`（MRR，多范围读取）的优化措施。
>
> 先读取一部分二级索引记录，将主键值排序好之后统一执行回表操作，相当与每读取一条二级索引记录就立刻回表这样会节省一些 IO 开销。

### 10.8.2 索引合并

MySQL 在一般情况下只会为单个索引生成扫描区间，但存在特殊情况，多个情况下 MySQL 也能为多个索引生成扫描区间，MySQL 的设计者把这种使用多个索引来完成一次查询的执行方法称为 `index merge`（索引合并），具体索引合并方法有以下三种：

#### `Intersection` 索引合并

例如这条查询：

```sql
select * from single_table where key1 = 'a' and key3 = 'b';
```

我们可以选择使用 `idx_key1` 或者 `idx_key3` 索引进行查询，由于是单点查询，所以查到的主键值其实是排序好的，然后再进行回表。

除了单独使用索引以外，还可以有方案3，具体如下：

> 同时使用 `idx_key1` 和 `idx_key3` 执行查询，也就是在 `idx_key1` 中扫描 key1 值为 'a' 的主键值，同时在 `idx_key3` 中扫描 key3 值为 'b' 的主键值，然后从两者的操作结果中找出 id 列值相同的记录，然后根据这些共有的 id 执行回表操作，这样可能节省很多回表操作带来的开销。

这个方案其实就是 `Intersection` 索引合并，其实就是取交集，只为这些 id 值执行回表操作，如果使用这种方式进行查询，则要求**每个索引中获取到的二级索引记录都是按照主键值排序的**。例如在上面的查询中在 `idx_key1` 的 ['a', 'a'] 扫描区间中的二级索引记录都是按照主键值排序的。

为什么要求索引记录按照主键值排序呢？主要是基于这两点考虑：

- 从两个有序集合中取交集比从两个无序集合取交集要容易得多。
- 如果获取的 id 是有序排列的，而在根据这些 id 执行回表操作就不再是进行单纯的随机 IO，会提高效率。

假设 `idx_key1` 扫描区间 ['a', 'a'] 中二级索引记录的 id 是排好序的，且顺序为 1、3、5，`idx_key3` 的扫描区间为['b', 'b']中二级索引记录的 id 也是排好序的，且顺序为2、3、4.那么这个查询步骤如下：

- 先从 `idx_key1` 获取第一条二级索引记录为1。然后从 `idx_key3` 获取第一条二级索引记录为2，因为 1<2，因此直接把 1 丢弃。
- 从 `idx_key1` 获取第二条二级索引记录为3。然后因为 `idx_key3` 的第一条二级索引记录为2，因为 2<3，因此直接把 2 丢弃。
- 从 `idx_key3` 获取第二条二级索引记录为3。然后因为 `idx_key1` 的第二条二级索引记录为3，因为 3=3，因此回表将 id 为 3 的记录发送到客户端。
- 从 `idx_key1` 获取第三条二级索引记录为5。然后从 `idx_key3` 获取第三条二级索引记录为4，因为 4<5，因此直接把 4 丢弃。
- 从 `idx_key3` 扫描的区间取出下一条符合的二级索引记录，发现没了，直接结束查询。

如果使用某个二级索引执行查询但是对应的二级索引记录不是按照主键值排序，则不可以使用 `Intersection` 索引合并来执行查询，例如下面这个查询：

```sql
select * from single_table where key1 > 'a' and key3 = 'b';
```

其中 `key1 > 'a'` 这条语句查询的 id 不是有序的，所以不能使用索引合并。

例如：

```sql
select * from single_table where key1 = 'a' and key_part1 = 'a';
```

在 `idx_key_part` 二级索引中 `key_part1 = 'a'` 的记录的 id 值不是有序的，因此也不能使用 `Intersection` 索引合并的方式进行。

另外聚簇索引是比较特殊的存在，因为聚簇索引就是按照主键值进行排序的，例如下面这个查询：

```sql
select * from single_table where key1 = 'a' and id > 9000;
```

就可以执行 `Intersection` 索引合并。

#### `Union` 索引合并

例如这条查询：

```sql
select * from single_table where key1 = 'a' or key3 = 'b'
```

我们不能仅使用 `idx_key1` 或者 `idx_key3` 执行上述查询。以 `idx_key1` 为例，如果只使用 `idx_key1` 执行查询，那么对应扫描区间就是 
`(-∞, +∞)`，而且还要回表，这样就是 all 访问方法了。

我们可以同时使用 `idx_key1` 与 `idx_key3` 执行查询，在 `idx_key1` 与 `idx_key3` 查询到的主键值执行并集运算那么得到的 id 值就是我们需要的值。

不过这里要注意，执行并集要去除重复的元素，所以这里也要求查询的记录的主键要按照主键进行排序。

- 从两个有序集合执行去重操作比两个无序集合去重容易实现。
- 如果获取的 id 是有序的话，根据这些 id 值进行回表操作就不是进行单纯的随机 IO，可以提高效率。

#### `Sort-Union` 索引合并

`Union` 索引合并使用条件苛刻，必须保证各个索引扫描的记录的主键值是有序的，例如下面这个查询就无法使用 `Union` 索引合并：

```sql
select * from single_table where key1 < 'a' or key3 >'z';
```

不过 `key1 < 'a' 和 key3 >'z'` 这两个条件又很特别，我们可以这样操作：

- 根据 `key1 < 'a'` 从 `idx_key1` 中获取二级索引记录，将获取到的二级索引记录的主键值进行排序。
- 根据 `key3 > 'z'` 从 `idx_key3` 中获取二级索引记录，将获取到的二级索引记录的主键值进行排序。
- 剩下的操作就和 `Union` 索引合并相同了。

> 为啥有 `Sort Union` 但没有 `Sort Intersction` 呢。
>
> 按照个人理解 `Sort Union` 索引合并针对 **单独根据搜索条件从某个二级索引中获取的记录数较少**，这样即使排序，成本也不会太高。
>
> 而 `Intersection` 索引合并针对的是 **单独根据搜索条件从某个二级索引中获取的记录数太多**，导致回表成本太大的场景，如果排序的话成本就太高了。因此才没有 `Sort Intersction`

# 十一章. 连接的原理

## 11.1 连接简介

### 11.1.1 连接本质

首先建两张表：

```sql
create table t1 (m1 int, n1 char(1));

create table t2 (m2 int, n2 char(1));
```

​                              <img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220513154043413.png" alt="image-20220513154043413" style="zoom:33%;" />                                 <img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220513154058826.png" alt="image-20220513154058826" style="zoom: 44%;" />    

本质上来说，连接就是将各个表中的记录都取出来进行依次匹配，并把匹配后的组合发送给客户端。 t1 和 t2 表连接如图：

<img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220513154938590.png" alt="image-20220513154938590" style="zoom:50%;" />

简单来说就是笛卡尔积，在 MySQL 中，我们也可以直接用 select from 达成相同的效果：

```sql
select * from t1, t2;
```

### 11.1.2 连接过程简介

我们可以连接任意数量的表，如果不加任何限制条件那么连接产生的笛卡尔积可能是巨大的。在连接查询过程中的过滤条件可以分为以下两种：

- 涉及单表条件：例如 t1.m1 > 1 是只针对 t1 表的过滤条件。
- 涉及两表条件：例如 t1.m1 = t2.m2，t1.n1 > t2.n2

例如这条查询语句：

```sql
select *
from t1, t2
where t1.m1 > 1 and t1.m1 = t2.m2 and t2.n2 < 'd';
```

指明三条过滤条件：t1.m1 > 1、t1.m1 = t2.m2、t2.n2 < 'd'

这个连接查询执行过程大致如下：

1. **首先确定第一个需要被查询的表，这个表称为驱动表**。

   这里假设以 t1 表作为驱动表，需要到 t1 表中查找满足 t1.m1 > 1 的记录，因此我们可以找到如下记录：

   <img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220513160520420.png" alt="image-20220513160520420" style="zoom:50%;" />

2. **第 1 步从驱动表中每获取到一条记录，到要到 t2 表中查询匹配记录**。

   根据上一步获取的每一条距离，一一到 t2 表中匹配数据。

   <img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220513160807786.png" alt="image-20220513160807786" style="zoom:50%;" />

最后可以查出两条记录。

以上查询需要查一次 t1 表，查两次 t2 表，如果从 t1 中查出 n 条记录，那么就要查 n 次 t2 表。

### 11.1.3 内连接和外连接

```mysql
create table student {
	number int not null auto_increment comment '学号',
	name varchar(5) comment '姓名',
	major varchar(30) commont '专业',
	primary key (number)
} engine = InnoDB charset = utf8 comment '学生信息表';

create table score {
	number int comment '学号',
	subject varchar(30) comment '科目',
	score tinyint comment '成绩',
	primary key (number, subject)
} engine = InnoDB charset = utf8 comment '学生成绩表';
```

插入数据后的表：

<img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220513161714043.png" alt="image-20220513161714043" style="zoom:50%;" />

现在想把学生的信息和成绩都查询出来就需要两表连接了。

```mysql
select * from student, score where student.number = socer.number;
```

![image-20220513162113583](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220513162113583.png)

可是这里有个问题，王五没有成绩，如果老师想查看所有学生的考试成绩，即使是缺考，也应该展示出来，但是目前为止我们介绍的连接查询无法完成这样的要求。因为我们之前的连接查询是从驱动表中查出字段，到被驱动表中匹配，但是被驱动表中可能根本就没有这样的记录，当然查不出来。

为了解决这个问题，就有了内连接和外连接的概念。

- 对于**内连接**的两表，若驱动表中的记录在被驱动表中找不到匹配的记录，该记录不会加入结果集。之前提到的都是内连接。
- 对于**外连接**的两表，即使驱动表的记录在被驱动表中没有匹配，也会加入到结果集中。

在 MySQL 中，根据选取的驱动表的不同，外连接可以分为两种：

- 左外连接：选取左侧的为驱动表
- 右外连接：选取右侧的为驱动表

可是会存在这样的问题，对于外连接，有时我们不想把驱动表的全部记录都加入到最后的结果集。

- Where 子句中的过滤条件

  where 子句的过滤条件就是我们平时常见的，不论是内外连接，凡是不符合 where 子句的都不会被加入到最后的结果集。

- On 子句的过滤条件

  对于外连接的驱动表中的记录来说，如果无法在被驱动表中找到匹配 On 子句的过滤条件的记录，那么驱动表的记录会被加入到结果集中，对应的被驱动表记录的各个字段用 Null 填充。

需要注意，这个 on 子句是专门为 "==外连接驱动表==的记录在==被驱动表==中找不到匹配记录时，是否将驱动表记录加如结果集中"。

所以如果把 on 子句添加到内连接，MySQL 会像 Where 那样对待 on 子句。内连接中 where 子句和 on 子句是等价的。

#### 左外连接语法

例如我们要将 t1 表和 t2 表进行左外连接查询，可以这么写：

```mysql
select * from t1 left [outer] join t2 on 连接条件 [where 普通过滤条件];
```

其中 outer 可以省略。对于左连接类型的连接，我们把放在左边的表称为外表或者驱动表，放在右边的表称为内表或者被驱动表。

所以上述查询中 t1 是驱动表， t2 是被驱动表。

注意： 对于左外连接和右外连接，必须用 ON 子句来指明连接条件。

之前示例的实现：

```mysql
select s1.number, s1.name, s2.subject, s2.score 
from student as s1 
left join score as s2
on s1.number = s2.number;
```

<img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220513170326822.png" alt="image-20220513170326822" style="zoom:50%;" />

#### 右外连接语法

右外连接和左外连接原理相同，语法只是将 left 换成 right 而已

```mysql
select * from t1 right [outer] join t2 on 连接条件 [where 普通过滤条件]
```

右外连接中，驱动表是右边的表即 t2，被驱动表示左边的表即 t1

#### 内连接语法

内连接和外连接根本区别就在于驱动表中不符合 on 子句的连接条件时，内连接不会将该记录加入到最后的结果集中。

```sql
select * from t1 [inner | cross] join t2 [on 连接条件] [where 普通过滤条件]
```

也就是说在 MySQL 中，下面几种写法等价：

- `select * from t1 join t2`
- `select * from t1 inner join t2`
- `select * from t1 cross join t2`
- `select * from t1, t2`

推荐用 `inner join` 写内连接，因为语义明确。

#### 总结

连接就是将各个表中的记录都取出来依次进行匹配，并将匹配后的组合发送给客户端。无论那个表作为驱动表，两表产生的笛卡尔积肯定一样。

对于内连接来说，不符合 On 或者 where 条件的记录全部过滤。对于内连接，驱动表和被驱动表可以互换，不会影响结果。

对于外连接，由于驱动表的记录在被驱动表找不到符合 on 的记录，也会被加入到结果集，此时驱动表和被驱动表的关系就很重要了，外连接的驱动表和被驱动表不能轻易互换，

<img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220513173450691.png" alt="image-20220513173450691" style="zoom:50%;" />

## 11.2 连接的原理

### 11.2.1 嵌套循环连接

对于两表连接，驱动表只会被访问一次，但被驱动表要被访问很多次，具体访问几次取决于驱动表查出多少条数据。

对于内连接，选哪个表为驱动表都没有关系，外连接的驱动表的选取是固定的，左连接就是左表，右连接就是右表。

1. 选取驱动表，使用与驱动表相关的过滤条件，选取代价最低的单表访问来执行对驱动表的单表查询。
2. 对步骤 1 的查询驱动表得到的结果集中的每条记录，分别到被驱动表查找匹配记录。

![image-20220513181601147](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220513181601147.png)

如果有 3 个表连接，那么步骤 2 得到的结果集就是新的驱动表，然后第 3 个表成了被驱动表，重复上面的过程。

```
for each row in t1 satisfying coditions about t1 {
	for each row in t2 satisfying coditions about t2 {
		for each row in t3 satisfying coditions about t3 {
			
			send to client;
			
		}
	}
}
```

### 11.2.2 使用索引加快连接速度

在嵌套循环连接中可能需要访问多次被驱动表。如果访问被驱动的方式都是全表扫描，那需要扫描很多次。但是查询 t2 表相当于一次单表查询，我们可以利用索引来加快查询速度。

```sql
select * from t1, t2 where t1.m1 > 1 and t1.m1 = t2.m2 and t2.n2 < 'd';
```

这个连接查询使用的是嵌套循环连接算法，查询执行过程：

<img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220513160807786.png" alt="image-20220513160807786" style="zoom:50%;" />

查询驱动表 t1 后结果集有 2 条记录，嵌套循环连接需要查询被驱动表 2 次。

- t1.m1 = 2时，查询一次 t2 表，对 t2 表查询相当于：

  ```sql
  select * from t2 where t2.m2 = 2 and t2.n2 < 'd';
  ```

- t1.m1 = 3时，查询一次 t2 表，对 t2 表查询相当于：

  ```sql
  select * from t2 where t2.m2 = 3 and t2.n2 < 'd';
  ```

原来的 t1.m1 = t2.m2 这个条件在针对 t2 表查询时关于 t1 的条件已经确定，所以只需要单单优化对 t2 的查询即可，上述利用到 m2、n2 列，因此可以这样尝试：

- 在 m2 上建立索引。因此对 m2 是等值查找，所以可能用到 ref 访问方法。之后再回表判断 t2.n2 < 'd' 是否成立即可。
- 在 n2 上建立索引。条件是 `t2.n2 < 'd'`，用到 range 访问方法，如果使用 range 那么需要回表判断包含 m2 的条件是否成立。
- 假设 m2 和 n2 上都有索引，那就从中挑选一个代价更低的索引来查询 t2。

假设连接查询的查询列表和过滤条件有可能只涉及被驱动表的部分列，来自某个多列索引的一部分，这样可以通过扫描全部二级索引记录来查询被驱动表，所以不要使用 * 作为查询列表，把真正用到的列作为查询列表。

### 11.2.3 基于块的嵌套循环连接

MySQL 设计者设计了一个名为 `Join Buffer` 的内存缓冲区，用于存放 **驱动表** 结果集的若干条记录放入 `Join Buffer` 中，好处是减少被驱动表 IO 次数。

如果驱动表每筛选一条记录就去被驱动表中筛选其他记录的话，那么被驱动表就要经历多次磁盘 IO，而如果，我们能将多条驱动表结果集放入缓冲池，再根据这些结果集到被驱动表进行筛选，那么磁盘 IO 的次数就大大下降，最好的情况是驱动表全部加载到 `Join Buffer` 中，这样被驱动表磁盘 IO 的次数只有 1 次（两表连接）。

这个 `Join Buffer` 可以通过系统变量进行设置 `join_buffer_size`，默认大小为 256 KB，最小是 128 byte。

Join Buffer 只会存放驱动表被筛选的所有列。

这也是为什么不用 * 作为查询列表，以便于 join buffer 能存放更多记录。

# 十二章. 基于成本的优化

## 12.1 什么是成本

- IO 成本：我们表常用的 `MyISAM`、`InnoDB` 存储引擎都是将数据和索引存储到磁盘上。当查询到表中记录时，需要先把数据或者索引加载到内存中，然后再进行操作。这个从磁盘到内存的加载过程损耗的时间称为 IO 成本。
- CPU 成本：读取记录以及检测记录是否满足对应的搜索条件、对结果集进行排序这些操作损耗的时间称为 CPU 成本。

对 `InnoDB` 存储引擎来说，页是磁盘与内存之间进行交互的基本单位。MySQL 设计者规定：读取一个页的成本为 1.0；读取以及检测一条记录是否符合搜索条件的成本默认是0.2。

## 12.2 单表查询的成本

### 12.2.1 准备 `single_table`

```sql
create table single_table (
	id int not null AUTO_INCREMENT,
	key1 varchar(100),
	key2 int,
	key3 VARCHAR(100),
	key_part1 varchar(100),
	key_part2 varchar(100),
	key_part3 varchar(100),
	common_field varchar(100),
	primary key(id),
	key idx_key1 (key1),
	unique key uk_key2 (key2),
	key idx_key3 (key3),
	key idx_key_part (key_part1, key_part2, key_part3)
) Engine=InnoDB charset=utf8;
```

假设这张表有 10,000 条记录，除 id 列外其余的列都插入随机值。

### 12.2.2 基于成本的优化步骤

真正执行一条单表查询语句前，MySQL 的优化器会找出所有可以用来执行该语句的方案，并在对比这些方案后找出成本最低的方案，也就是执行计划，步骤如下：

1. 根据搜索条件，找出所有可能使用的索引。
2. 计算全表扫描的代价。
3. 计算使用不同索引执行查询的代价。
4. 对比各种执行方案的代价，找出成本最低的方案。

例如一条查询语句：

```sql
select * from single_table
where key1 in ('a', 'b', 'c') 
and key2 > 10 and key2 < 1000
and key3 > key2
and key_part1 like '%hello%'
and common_field = '123';
```

分析：

#### 根据搜索条件，找出所有可能使用的索引

MySQL 的设计者将一个查询可能用到的索引称为 `possible keys`

- `key1 in ('a', 'b', 'c')`  使用二级索引 `idx_key1`
- `key2 > 10 and key2 < 1000` 使用二级索引 `uk_key2`
- `key3 > key2` 没有与常数比较，所以不能产生合适的扫描区间
- `key_part1 like '%hello%'` 通过 Like 操作符与以通配符开头的字符串比较，不能产生合适的扫描区间。
- `common_field='123'` 没有索引

综上：`possible keys` 为 `idx_key1` 与 `uk_key2`

#### 计算全表扫描的代价

对 `InnoDB` 来说，全表扫描意思就是将聚簇索引中的记录都依次与给定的搜索条件进行比较，并把符合搜索条件的记录加入到结果集中。所以需要将聚簇索引对应的页面加载到内存中，然后检测记录是否符合搜索条件。查询成本 = IO 成本 + CPU 成本，所以计算全表扫描代价需要两个信息：

- 聚簇索引占用的页面数。
- 表中记录数。

这两个信息可以用 `show table status like '表名'\G` 来展示

![image-20220515144500127](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220515144500127.png)

我们只要关心其中两个选项即可：

- Rows：表示表中记录条数。对于 `MyISAM` 来说该值是准确的，对于使用 `InnoDB` 来说，该值是一个估值。表中有 10,000 条记录，这里只显示 9,693 条。

- Data_length：表示表占用的存储空间字节数。对于 `MyISAM` 来说，就是数据文件大小，对于 `InnoDB` 来说，该值就相当于聚簇索引占用的存储空间大小。

  ```
  Data_length = 聚簇索引页面数量 x 每个页面大小
  
  聚簇索引页面数量 = Data_length / 每个页面大小 
  ```

  所以我们这里的页面数量 = 1,589,248 / 16 / 1024 = 97

得到页面数量与记录数就可以得到全表扫描代价了，不过计算时会有一个微调值，不大，不影响大体数值。

- IO 成本：97 x 1.0 + 1.1 = 98.1

  1,1 为微调值。

- CPU 成本：9,693 x 0.2 + 1.0 = 1939.6

  1.0 为微调值

- 总成本：98.1 + 1939.6 = 2037.7

所以全表扫描的总成本就是 2037.7

#### 计算使用不同索引执行查询的代价

注意这里MySQL 最后也会分析是否可能使用索引合并。

1. 使用 `uk_key2` 执行查询的成本分析

   `uk_key2` 对应的搜索条件是 `key2 > 10 AND key2 < 1000`，对应的扫描区间就是（10，1000）。使用二级索引然后回表即可。

   ![image-20220515150315226](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220515150315226.png)

   - 扫描区间数量

     无论某个扫描区间的二级索引到底占多少页面，优化器粗暴地认为读取索引的一个扫描区间的 IO 成本与读取一个页面的 IO 成本相同。本例中区间为（10,1000），相当于访问这个扫描区间的二级索引付出的 IO 成本就是 1 x 1.0 = 1.0

   - 回表的记录数

     优化器需要计算二级索引的某个扫描区间到底包含多少条记录，计算过程如下：

     1. 根据 key2 > 10 条件访问 `uk_key2` 对应的 B+ 树索引，找到满足 key2 > 10 的第一条记录（最左记录），这步很快，消耗可以忽略。

     2. 根据 key2 < 1000 条件从 `uk_key2` 对应的 B+ 书索引找出最后一条满足这个条件的记录（最右记录），很快，消耗忽略。

     3. 如果最左记录和最右记录相隔不远（不大于 10 个页面），就可以精确统计这个条件的二级索引记录条数。

        否则只沿着区间最左记录向右读 10 个页面，计算每个页面平均含多少记录，然后用平均值乘以页数即可。

        那么如何计算最左记录与最右记录之间有多少页面呢？

        ![image-20220515152141972](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220515152141972.png)

        计算父节点中最左记录所在的页的记录与最右记录所在页的记录之间的条数即可，如果页太多，那就递归调用即可。

        假设(10, 1000) 之间大约有 95 条记录，读取这 95 条记录需要付出的 CPU 成本就是 95 x 0.2 + 0.01 = 19.01，0.01 是微调值。计算后还要做两件事：

        - 根据记录的主键值到聚簇索引中执行回表操作。

          MySQL 设计者认为每次回表都相当于访问一个页面，也就是说多少条记录就访问多少条页面，所以这里的成本就是 95 x 1.0 = 95.0

        - 回表操作得到完整用户记录，检测其他搜索条件是否成立。

          读取到聚簇索引记录后还要判断它是否满足其他条件，代价为 95 x 0.2 = 19.0

   总代价就是95.0 + 1.0 + 95 x 0.2 + 0.01 + 95 x 0.2 = 134.01。

2. 使用 `idx_key1` 执行查询的成本分析

   条件是 `key1 in ('a', 'b', 'c')`，相当于三个单点扫描区间：`['a','a']、['b', 'b']、['c', 'c']`

   如下图：

   ![image-20220515152919198](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220515152919198.png)

   - 扫描区间数量：3个单点扫描，因此 IO 成本为 3 x 1.0

   - 需要回表的记录数

     - 扫描 'a' 对应的二级索引记录数，也是先找到最左记录与最右记录，最后得到 'a' 对应的二级索引记录数是 35
     - 扫描 'b' 对应的二级索引记录数，44条
     - 扫描 'c' 对应的二级索引记录数，39 条

     因此需要回表的记录数是 35 + 44 + 39 = 118，CPU 成本是 118 x 0.2 + 0.01 = 23.61

   - 回表查询，IO 成本为 118 x 1.0 = 118.0

   - 判断其他搜索条件 118 x 0.2 = 23.6

   成本 = 3 + 118 + 23.61 + 23.6 = 168.21

3. 是否可能使用索引合并

   由于查找的二级索引不是按照主键值进行排序（都是范围查询），所以不能使用 `Intersection` 合并的条件

4. 找出成本最低的方案

   这里使用 `uk_key2` 的成本最低，所以选择 `uk_key2` 执行查询

### 12.2.3 基于索引统计数据的成本计算

使用索引执行查询时会有很多单点扫描区间，使用 IN 语句就容易产生很多单点扫描区间，例如：

```sql
select * from single_table where key1 in ('aa1', 'aa2', 'aa3', ..., 'zzz');
```

由于这个索引不是唯一二级索引，不能确定一个单点扫描区间内对应的二级索引记录的条数有多少，需要计算，就是前面提过的最左记录和左右记录，计算这两条记录之间有多少记录。

MySQL 设计者将这种通过直接访问索引对应的 B+ 树来计算某个扫描区间内对应的索引记录条数的方式称为 `index dive`。

不过当 in 中参数过多就会导致性能直线下降，甚至可能不如全表扫描。MySQL 设计者也考虑到了这种情况，于是提供了一个系统变量 `eq_range_index_dive_limit` 默认值为 200.

如果 in 语句生成的单点扫描区间数量少于 200，将使用 `index dive`，否则不能使用 `index dive`，而是使用呢 **索引统计数据** 来进行估算。

像为每个表维护一份统计数据一样，MySQL 也会为表中的每一个索引维护一份统计数据，要查看某个表中索引的统计数据，可以使用 
`show index from 表名` 语法，例如：

![image-20220515160053110](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220515160053110.png)

每列的属性名和含义：

![image-20220515160423029](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220515160423029.png)

我们最在意的就是 `Cardinality` 属性，中文意思是 基数，表示某个列中不重复的值的个数，对于有 10,000 行记录的表来说，某个列的 `Cardinality` 属性如果为 10,000，表示这个列中没有重复的值，如果为 1，则表示全为重复的值。

假设 rows 值是 9693，key1 列的 `Cardinality` 值为 968，则可以计算 key1 列单个值的平均重复次数为10条。

```sql
select * from single_table where key1 in ('aa1', 'aa2', 'aa3', ..., 'zzz');
```

假设 IN 局域中对应着 20,000 个单点扫描区间，就直接使用统计数据来估算这些单点扫描区间对应的记录条数，每个单点扫描区间大约对应 10 条记录，所以总共需要回表的记录数就是 20,000 x 10 = 200,000

这种方式比 `index dive` 简便多了，缺点就是不精确。

## 12.3 连接查询的成本

### 12.3.1 准备

准备 single_table1 与 single_table2 它们的表结构和之前的 single_table 相同。

single_table1 简称 s1，single_table2 简称 s2

### 12.3.2 条件过滤

MySQL 中连接查询采用的是嵌套循环连接算法，驱动表只会访问一次，被驱动表会被访问多次，所以对于两表连接查询来说，它的查询成本由两部分构成：

- 单次查询驱动表的成本
- 多次查询被驱动表的成本

我们将 **查询驱动表后得到的记录条数** 称为驱动表的 **扇出**。驱动表的扇出值小，那么对被驱动表的查询次数也就越少，连接查询的成本也就越低。当查询优化器想计算执行整个查询的成本时，需要计算出驱动表的扇出值。

- 查询 1：

  ```sql
  select * from s1 inner join s2;
  ```

  s1 作为驱动表，只能使用全表扫描对驱动表进行单表查询，驱动表的扇出值也很明确，就是驱动表有多少记录，扇出值就是多少。

- 查询 2：

  ```sql
  select * from s1 inner join s2
  where s1,key2 > 10 and s1.key2 < 1000;
  ```

  s1 作为驱动表，那么根据索引 `uk_key2` 可以计算出 (10, 1000) 这个范围 s1 表的扇出值。

- 查询 3 ：

  ```sql
  select * from s1 inner join s2
  where s1.common_field > 'xyz';
  ```

  多了一个没有索引的列，优化器不会真正去查询满足这个条件有多少条记录，所以只能猜这些记录中有多少条记录满足这个条件。

- 查询 4：

  ```sql
  select * from s1 inner join s2
  where s1.key2 > 10 and s1.key2 < 1000
  and s1.common_field > 'xyz';
  ```

  与查询2类似，不过多了一个没有索引的列的条件，于是只要在 (10, 1000) 中利用二级索引，猜测这些条记录中有多少个记录满足 `common_field` 这个条件即可。

- 查询 5：

  ```sql
  select * from s1 inner join s2
  where s1.key2 > 10 and s1.key2 < 1000
  and s1.key1 in ('a', 'b', 'c')
  and s1.common_field > 'xyz';
  ```

  驱动表 s1 选取 `uk_key2` 后查询优化器需要猜测多少条记录满足

  - `s1.key1 in ('a', 'b', 'c')`
  - `s1.common_field > 'xyz'`

在下面两种情况计算驱动表扇出值时，需要靠猜测：

1. 使用全表扫描执行单表查询，计算驱动表扇出值要猜测满足全部搜索条件的记录有多少条。
2. 使用索引执行单表查询，计算驱动表扇出值需要猜测除了满足形成索引扫描区间的条件，还满足其他搜索条件的记录有多少条。

### 12.3.3 两表连接的成本分析

连接查询总成本 = 单次访问驱动表的成本 + 驱动表扇出值 x 单次访问被驱动表的成本

对于左连接和右连接查询来说，驱动表是固定的，所以只要考虑两个方面问题：

- 不同的表作为驱动表时，最终查询成本可能不同，也就是需要考虑最优的表连接顺序。
- 分别为驱动表和被驱动表选择成本最低的访问方法

以内连接为例看看如何计算最优的连接查询方案。

```sql
select * from s1 inner join s2
on s1.key1 = s2.common_field
where s1.key2 > 10 and s1.key2 < 1000
and s2.key2 > 1000 and s2.key2 < 2000;
```

可以选择的连接顺序有两种：

- s1 连接 s2，s1 驱动
- s2 连接 s1，s2 驱动

优化器需要考虑这两种情况下的查询成本，然后选择成本最低的连接顺序。

#### 使用 s1 作为驱动表

涉及 s1 的单表搜索条件有：`s1.key2 > 10 and s1.key2 < 1000`

这个查询使用 `uk_key2` 索引。

此时设计 s2 的搜索条件：`s2.key2 > 1000 and s2.key2 < 2000`、`s2.common_field = 常数` 

有用的条件为 `s2.key2 > 1000 and s2.key2 < 2000`，使用 `uk_key2` 索引。

所以成本为：使用 `uk_key2` 访问 s1 + s1 的扇出值 x 使用 `uk_key2` 访问 s2 的成本。

#### 使用 s2 作为驱动表

涉及 s2 的单表搜索条件有：`s2.key2 > 1000 and s2.key2 < 2000`

这个查询使用 `uk_key2` 索引。

此时涉及 s1 的搜索条件：`s1.key2 > 10 and s1.key2 < 1000`、`s1.key1 = 常数` 

有用的条件为 `s1.key2 > 10 and s1.key2 < 1000`，使用 `uk_key2` 索引 和 `s1.key1 = 常数`，使用 `idx_key1` 索引。

由于这里使用 `uk_key2` 执行方法为 range，而使用 `idx_key1` 执行方法为 ref，因此一般来说 ref 方法效率高。

所以成本为：使用 `uk_key2` 访问 s2 + s2 的扇出值 x 使用 `idx_key1` 访问 s1 的成本。

最终优化器会使用成本最低的执行查询，连接查询中占大头的是驱动表扇出 x 单词访问被驱动表的成本，所以优化重点就是：

- 减少驱动表扇出
- 访问被驱动表的成本尽量低

# 十四章. 基于规则的优化

有时虽然我们会写出很糟糕的 SQL，但是 MySQL 自身为尽力将这些糟糕的语句转换为某种可以高效执行的形式，这个过程可以称为查询重写。

## 14.1 条件化简

我们编写的查询语句的搜索条件本质上就是表达式，表达式可能比较复杂，MySQL 优化器会为我们化简这些表达式。

### 14.1.1 移除不必要的括号

有时表达式有无效的括号，例如：

```sql
select * from (t1, (t2, t3)) where t1.a = t2.a and t2.b = t3.b;
```

优化器会将不必要的括号移除，移除后：

```sql
select * from t1, t2, t3 where t1.a = t2.a and t2.b = t3.b;
```

### 14.1.2 常量传递

有时某个表达式是某个列和某个常量的等值匹配，例如：

```sql
a = 5
```

当使用 AND 操作符将这个表达式和其他设计列 a 的表达式连接起来时，可以将其他表达式中的 a 的值替换为 5，例如：

```sql
a = 5 AND b > a
```

可以被转换为

```sql
a = 5 AND b > 5
```

> 但是使用 OR 操作符的话就不能进行常量传递了。

### 14.1.3 移除没用的条件

对于一些明显为 TRUE 或者 FALSE 的表达式，优化器会将它们移除掉，例如：

```sql
(a < 1 AND b = b) OR (a = 6 OR 5 != 5)
```

优化为：

```sql
(a < 1 AND TRUE) OR (a = 6 OR false)
```

继续简化：

```sql
a < 1 OR a = 6
```

### 14.1.4 表达式计算

查询执行之前，如果表达式只包含常量，它就会被先计算出来，例如：

```sql
a = 5 + 1
```

会被化简为：

```sql
a = 6
```

但是如果某个列不是以单独的形式作为表达式的操作数，例如出现在函数中，或者出现在更复杂的表达式中，例如：

```mysql
abs(a) > 5

-a < -7
```

优化器是不会尝试对这些表达式进行化简的。

### 14.1.5 `HAVING` 子句和 `WHERE` 子句

如果查询语句没有出现例如 SUM、MAX 这样的聚集函数以及 GROUP BY 子句，查询优化器会把 HAVING 子句和 WHERE 子句合并

### 14.1.6 常量表检测

MySQL 设计者认为下面两种类型的查询会执行的很快：

- 查询的表中一条记录也没有或者只有一条

  > 由于 `InnoDB` 统计信息不准确，所以不适用

- 使用主键等值匹配或者唯一二级索引列等值匹配作为搜索条件来查询某张表。

MySQL 设计者认为这 2 种查询花费的时间很少，少到可以忽略，所以把通过这两种方式查询的表称为 **常量表**，查询优化器在分析一个查询语句时，首先执行常量表查询，然后将查询中涉及该表的条件全部替换为常数，最后分析其余表的查询成本。

例如如下查询：

```sql
select * from t1 inner join t2
on t1.c1 = t2.c2
where t1.primary_key = 1;
```

这里是按照主键查找，因此与 t1 有关的数据可以全部替换为常数：

```sql
select t1 记录的各个字段的常量值， t2.* from t1 inner join t2
on t1.c1常量值 = t2.c2;
```

## 14.2 外连接消除

内连接的驱动表和被驱动表是可以互换的，这就意味着内连接可以优化表的连接顺序来降低整体的查询成本。

而外连接的驱动表和被驱动表不可以互换，所以外连接无法优化表的连接顺序。

首先建两张表：

```sql
create table t1 (m1 int, n1 char(1));

create table t2 (m2 int, n2 char(1));
```

​                              <img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220513154043413.png" alt="image-20220513154043413" style="zoom:33%;" />                                 <img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220513154058826.png" alt="image-20220513154058826" style="zoom: 44%;" />    

外连接和内连接的本质区别是：对于外连接的驱动表记录来说，如果无法在被驱动表中找到匹配 ON 子句中过滤条件的记录，那么该驱动表记录仍然会被加入到结果集中，对应的被驱动表记录的各个字段使用 NULL 值填充；而内连接驱动表记录如果无法在被驱动表中找到匹配 ON 子句中过滤条件的记录，那么该驱动表记录会被舍弃，查询效果如下：

![image-20220516161002937](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220516161002937.png)

我们知道 WHERE 子句杀伤力较大，凡是不符合 WHERE 子句中条件的记录都不会参与连接。只要我们在 WHERE 子句的搜索条件中指定 "被驱动表的列不为 NULL" 的搜索条件，那么外连接中在被驱动表中找不到符合 ON 子句条件的驱动表记录也就从最后的结果集中被排除了，那么在这种情况下，外连接和内连接就没有什么区别了。如下：

![image-20220516162023187](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220516162023187.png)

所以这样外连接就可以转换为内连接，这样的条件称为**空值拒绝**，好处是优化器可以通过评估表的不同连接顺序的成本，选出成本最低的连接顺序来执行查询。

## 14.3 子查询优化

### 14.3.1 子查询语法

- 在 SELECT 子句中

  ```sql
  select (select m1 * from t1 limit 1);
  ```

  其中 `(select m1 * from t1 limit 1)` 就是子查询

- 在 FROM 子句中

  ```sql
  select m, n from (select m2 + 1 AS m, n2 AS n from t2 where m2 > 2) AS t;
  ```

  这个例子中的子查询是 `(select m2 + 1 AS m, n2 AS n from t2 where m2 > 2)`，它出现在了 FROM 子句中，我们可以将子查询的结果看做是一张表，as t 意思就是这个子查询的结果就是一张名为 t 的表。我们将这种放在 FROM 子句后面的子查询称为**派生表**。

- 在 WHERE 或 ON 子句的表达式中

  我们最常用子查询的方式是将子查询放在外层查询的 WHERE 子句或者 ON 子句的表达式中，例如：

  ```sql
  select * from t1 where m1 in (select m2 from t2);
  ```

  这个查询表明我们想将 `(select m2 from t2)` 这个子查询的结果作为外层查询的 IN 语句参数。

- 在 ORDER BY 子句中

  语法支持，但是没啥意义

- GROUP BY 子句中

  语法支持，没啥意义

#### 按返回的结果集区分子查询

- 标量子查询：只返回一个单一值的子查询称为标量子查询

  ```sql
  select (select m1 from t1 limit 1);
  ```

  或者：

  ```sql
  select * from t1 where m1 = (select MIN(m2) from t2);
  ```

- 行子查询：返回一条记录的子查询，不过这条记录要包含多列，如果只有一列，那就是标量子查询

  ```sql
  select * from t1 where (m1, n1) = (select m2, n2 from t2 limit 1);
  ```

- 列子查询：查询一个列的数据，不过要包含多行

  ```sql
  select * from t1 where m1 in (select m2 from t2);
  ```

- 表子查询：子查询的结果包含多行多列记录

  ```sql
  select * from t1 where (m1, n1) in (select m2, n2 from t2);
  ```

#### 按与外层查询的关系来区分子查询

  - 不相关子查询

    子查询可以单独运行出结果，不依赖于外层查询的值，可以将这个子查询称为不相关子查询，之前写的 SQL 都是不相关子查询。

  - 相关子查询

    如果子查询的执行需要依赖于外层查询的值，可以将这个子查询称为相关子查询，例如：

    ```sql
    select * from t1 where m1 in (select m2 from n1 = n2);  # 这里 n1 是 t1 表中的列
    ```

    子查询中有一个搜索条件为 `n1 = n2`，其中 n1 为外层查询的列，所以这个子查询就是一个相关子查询。

#### 子查询在布尔表达式中的使用

- 使用=、>、<、>=、<=、<>、!=、<=> 作为布尔表达式的操作符

  > `<=>`为NULL安全的等值比较运算符（NULL-safe equal），该操作符作用类似“=”。区别为当符号两边出现NULL值时，`=`操作符会返回NULL，而`<=>`会返回 1（两边操作数都为NULL时）或者 0（一边操作数为NULL）。

  ```sql
  select * from t1 where m1 < (select min(m2) from t2);
  ```
  
  或者
  
  ```sql
  select * from t1 where (m1, n1) = (select m2, n2 from t1 limit 1);
  ```
  
- `[NOT] IN/ANY/SOME/ALL` 子查询

  - IN 或者 NOT IN

    ```sql
    操作数 [NOT] IN (子查询)
    ```

    判断某个操作数是否存在于由子查询结果集组成的集合中，如下：

    ```sql
    select * from t1 where (m1, n1) in (select m2, n2 from t2);
    ```

  - ANY/SOME（ANY 和 SOME 表达意思相同）

    ```sql
    操作数 比较符 ANY/SOME(子查询)
    ```

    只要在子查询的结果集中存在一个值，某个指定的操作数与该值通过 比较符 进行比较时，结果为 TRUE，那么这个表达式的结果就位 TRUE，否则整个表达式的记过为 FALSE，例如：
    
    ```mysql
    select * from t1 where m1 > ANY(select m2 FROM t2);
    ```
    
    本质上等价于：
    
    ```sql
    select * from t1 where m1 > (select MIN(m2) FROM t2);
    ```
    
    =ANY 表示子查询结果集中是否存在某个值等于给定的操作数，含义和 IN 相同
    
  - ALL
  
    ```sql
    操作数 比较符 ALL(子查询)
    ```
  
    指定的操作数与该子查询结果集中所有的值通过 比较符 进行比较时结果都为 TRUE，那么整个表达式的结果就是 TRUE，否则为 FALSE
  
    ```sql
    select * from t1 where m1 > ALL(select m2 from t2);
    ```
  
    等价于：
  
    ```sql
    select * from t1 where m1 > (select MAX(m2) from t2);
    ```
  
- EXISTS 子查询
  
    ```sql
    [NOT] EXISTS (子查询)
    ```
  
    下面这个例子：
  
    ```sql
    select * from t1 where exists (select 1 from t2);
    ```
  
    我们不用管这个子查询最后查询的结果到底有多少条记录，关键在于有没有，如果有则相当于 TRUE，没有则相当于 FALSE
    
    

#### 子查询语法注意

- 子查询必须用小括号括起来

  ```sql
  # 错误示范
  select select m1 from t1;
  ```

- 在 select 子句中的子查询必须是标量子查询，如果子查询结果集有多行多列，不允许放在 select 子句中，例如：

  ```sql
  select (select m1, n1 from t1);
  ```

- 对于 `[NOT] IN/ANY/SOME/ALL` 子查询来说，子查询中不允许有 limit 语句

- 不允许在一条语句中增删改某个表的记录时，同时还对该表进行子查询，例如：

  ```sql
  delete from t1 where m1 < (select max(m1) from t1);
  ```

### 14.3.2 子查询在 MySQL 是怎么执行的

创建 single_table 表：

```sql
create table `single_table` {
	`id` int not null auto_increment,
	`key1` varchar(100),
	`key2` int,
	`key_part1` varchar(100),
	`key_part2` varchar(100),
	`key_part3` varchar(100),
	`common_field` varchar(100),
	primary key(id),
	key idx_key1 (key1),
	unique key uk_key2 (key2),
	key idx_key3 (key3),
	key idx_key_part (key_part1, key_part2, key_part3)
} Engine=InnoDB charset=utf8;
```

假设 s1、s2 与 single_table 表结构相同，且两张表中有 10,000 条记录。

#### 标量子查询、行子查询的执行方式

使用场景：

- 在 select 语句中
- 子查询使用 =、>、<、>=、<=、<>、!=、<=> 等操作符和某个操作数组成一个布尔表达式，这样的子查询必须是标量子查询或者行子查询。

如下面这个查询语句：

```sql
select * from s1
where key1 = (select common_field from s2 where key3 = 'a' LIMIT 1);
```

- 单独执行 `select common_field from s2 where key3 = 'a' LIMIT 1` 子查询
- 将查询的结果作为外层查询的参数，再执行外层查询。

对于相关的子查询，例如：

```sql
select * from s1 where key1 = (
    select common_field from s2 where s1.key3 = s2.key3 limit 1);
```

- 从外层查询中获取一条记录。
- 从这条记录找出子查询涉及的值。
- 根据子查询查询的结果检测外层查询 WHERE 子句条件是否成立，成立则加入结果集。
- 返回步骤 1，直到结束。

#### IN 子查询

1. 物化表的提出

   例如查询：

   ```sql
   select * from s1
   where key1 in (select common_field from s2 where key3 = 'a');
   ```

   执行过程不是简单的先计算出 `select common_field from s2 where key3 = 'a'` 再转化为 in 中的参数。

   对于不相关的 in 子查询来说，如果子查询结果集中的记录条数很少，那么将子查询和外层查询分别看成两个单表查询效率还是挺高的，但是如果结果集太多，就会导致内存太大甚至放不下。

   MySQL 设计者提出：不直接将不相关子查询的结果当做外层查询的参数，而是将该结果集写入一个临时表中。

   - 该临时表的列就是子查询结果集中的列。
   - 写入临时表的记录会被去重。（因为是 IN 操作）

   一般来说子查询结果集不会特别大，因此会为它建立基于内存使用 `MEMORY` 存储引擎的临时表，而且会为该表建立哈希索引（去重）。

   如果子查询的结果集很大，临时表会转换为使用基于磁盘的存储引擎来保存结果集中的记录，索引类型相应转换为 B+ 树索引。

   我们将这种 **子查询结果集记录保存到临时表的过程** 称为物化，将临时表称为 **物化表**

2. 物化表转连接

   ```sql
   select * from s1
   where key1 in (select common_field from s2 where key3 = 'a');
   ```

   当子查询物化完后，假设物化表名称为 mt，该表存储的子查询结果集的列称为 mc，那么这个查询可以从下面两个角度来看：

   - 从 s1 表角度：整个查询意思是对于 s1 的每条记录，如果 key1 值在 mt 中，则该记录会被加入结果集
   - 从 mt 角度：整个查询意思是对于 mt 的每个 mc 值来说如果能在 s1 中找到 s1.key1 = mt.mc 就把这些记录加入最终结果集

   上面的查询相当于 s1 与 mt 的内连接

   ```sql
   select s1.* from s1 inner join mt on key1 = mc;
   ```

   于是 MySQL 就会将这个查询转换为连接查询处理，用连接查询的方式进行优化。

3. 子查询转换为半连接

   将子查询物化再查询会有建立临时表的成本，但是可以转换为连接的强大作用。MySQL 的设计者继续考虑：能不能不进行物化，直接将子查询转换为连接呢？

   ```sql
   select * from s1
   where key1 in (select common_field from s2 where key3 = 'a');
   ```

   可以将这个查询理解为：对于 s1 表的某条记录，如果能在 s2 表（且 `s2.key3='a'`）找到 `s2.common_field = s1.key1`，那么该 s1 表的记录可以被加入到最终结果集，在这个过程起始于 `s1、s2` 两表连接起来效果很像：

   ```sql
   select s1.* from s1 inner join s2 
   on s1.key1 = s2.common_field
   where s2.key3 = 'a';
   ```

   不过我们不能保证对于 s1 的某条记录来说，在 s2 中能找到多少条记录满足 `s1.key1 = s2.common_field && s2.key2 = 'a'`，不过可以分类讨论：

   - 对于 s1 中的某条记录来说，s2 没有任何记录满足 `s1.key1 = s2.common_field && s2.key2 = 'a'`，该记录不会加入最终结果集
   - 对于 s1 某条记录来说，s2 有且只有一条满足条件，该记录会被加入最终结果集
   - 对于 s1 某条记录来说，s2 有多条满足条件，该记录会多次被加入最终结果集

   我们只关心 s2 是否有，而不关心有多少，因为第三种情况的存在，IN 子查询和两表连接查询并不完全等价，但是将子查询转换为连接可以充分发挥优化器的作用，所以 MySQL 设计者在这里提出一个新概念：**半连接**

   > 对于 s1 某条记录来说，只关心在 s2 表是否存在与之匹配的记录，不关心有多少条。

   ```sql
   # MySQL 并没有提供这种语法
   select s1.* from s1 SEMI JoIN s2
   on s1.key1 = s2.common_field
   where key3 = 'a';
   ```

   半连接的实现有很多种情况

   - **Table pullout 子查询的表上拉**

     适用于子查查询的查询列表是主键或者唯一索引，由于这种特性就导致它不可能重复。

   - **Duplicate Weedout 重复值消除**

     创建临时表，只为这张临时表设置一个主键，某条 s1 表记录要加入结果集时，将这条记录的 id 加入这个临时表，如果添加成功说明之前这条记录没有添加过，否则说明添加过，不添加即可。

   - **Loose Scan 松散扫描**

     将外层的搜索条件到子查询中查询，找到匹配的数据就返回并加入到结果集中。

   - **Semi-join Materialization 半连接物化**

   - **First Match 首次匹配**

4. 半连接的使用条件

   不是所有包含 IN 的子查询都可以使用半连接，只有形如这样的查询才可以转换：

   ```sql
   select ... from outer_tables
   where expr IN (select ... from inner_tables ...) [AND ...]
   ```

   或者

   ```sql
   select ... from outer_tables
   where (e1, e2...) IN 
   (select ie1, ie2, ... from inner_tables ...) [AND ...]
   ```

   - 必须是与 IN 操作符组成的布尔表达式，且在 ON / WHERE 子句中出现
   - 外层查询可以有其他搜索条件，不过必须使用 AND 且与 IN 查询的搜索条件连接起来
   - 子查询必须是单一查询
   - 子查询不能包含 Group By、Having 语句或者聚集函数

5. 不适用半连接的情况

   - 外层查询的 WHERE 子句存在 OR 与 IN 连接

     ```sql
     select * from s1 where key1 
     in (select common_field from s2 where key3 = 'a')
     or key2 > 100; 
     ```

   - 使用 not in 而不是 in

   - 位于 select 子句中的 in 子查询

     ```sql
     select key1 
     in (select common_field from s2 where key3 = 'a')
     from s1;
     ```

#### ANY/ALL 子查询优化

   如果 ANY/ALL 是不相关子查询，可以转换为熟悉的方式来执行

   ![image-20220516215636705](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220516215636705.png)

#### [NOT] EXISTS 子查询执行

   如果是不相关子查询，首先执行子查询，得出 EXISTS 子查询 的结果是 TRUE 还是 FALSE，然后重写 SQL 即可。

   如果不相关，只好一条一条查询了。

#### 对于派生表的优化

派生表就是指子查询放在 FROM 语句。

例如

```sql
select * from 
(select id as d_id, key3 as d_key3 from s2 where key1 = 'a')
as derived_s1
where d_key3 = 'a';
```

MySQL 提供两种执行策略：

- 派生表物化

  将派生表的结果集写入一个内部的临时表，然后将这个物化表作为普通表一样查询。

- 派生表和外层查询合并

  例如：

  ```sql
  select * from
  (select * from s1 where key1 = 'a') as derived_s1;
  ```

  等价于

  ```sql
  select * from s1 where key1 = 'a';
  ```

  对于一些派生表的复杂语句：

  ```sql
  select * from 
  (select * from s1 where key1 = 'a') as derived_s1 inner join s2
  on derived_s1.key1 = s2.key1
  where s2.key2 = 1;
  ```

  可以将派生表与外层查询合并，将派生表的搜索条件放到外层搜索条件，像：

  ```sql
  select * from s1 inner join s2
  on s1.key1 = s2.key1
  where s1.key1 = 'a' and s2.key2 = 1;
  ```

  

# 十五章. `Explain` 详解

如果我们想看某个查询的执行计划，可以在具体的查询语句前加一个 explain，如下：

![image-20220517115449819](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220517115449819.png)

其实除了 SELECT，其余的 delete、insert、update 都可以加 explain 这个词，用来查看这些语句的执行计划。

首先来看看各个列的作用：

| 列名          | 描述                                               |
| ------------- | -------------------------------------------------- |
| id            | 在一个大的查询语句中，每个 SELECT 都有对应的 id    |
| select_type   | SELECT 关键字对应的查询的类型                      |
| table         | 表名                                               |
| partitions    | 匹配的分区信息                                     |
| type          | 针对单表的访问方法                                 |
| possible_keys | 可能使用到的索引                                   |
| key           | 实际使用的索引                                     |
| key_len       | 实际使用的索引长度                                 |
| ref           | 当使用索引列查询时，与索引列进行等值匹配的对象信息 |
| rows          | 预估的需要读取的记录条数                           |
| filtered      | 针对 rows，经过搜索条件过滤后剩余记录条数的百分比  |
| extra         | 额外信息                                           |

首先还是创建一张 single_table 表：

```sql
create table single_table (
	id int not null AUTO_INCREMENT,
	key1 varchar(100),
	key2 int,
	key3 VARCHAR(100),
	key_part1 varchar(100),
	key_part2 varchar(100),
	key_part3 varchar(100),
	common_field varchar(100),
	primary key(id),
	key idx_key1 (key1),
	unique key uk_key2 (key2),
	key idx_key3 (key3),
	key idx_key_part (key_part1, key_part2, key_part3)
) Engine=InnoDB charset=utf8;
```

## 15.1 各列意义

### 15.1.1 table

无论查询语句多复杂，里面包含多少张表，最后也是对每个表进行单表访问，所以 MySQL 设计者规定：EXPLAIN 语句输出的每条记录都对应着某个单表的访问方法，该条记录的 table 代表该表的表名。

例如：

```mysql
explain select * from s1;
```

![image-20220517141021367](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220517141021367.png)

这里是对 s1 进行单表访问，所以 table 就是 s1

```sql
explain select * from s1 inner join s2;
```

![image-20220517141218942](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220517141218942.png)

两条记录的 table 分别是 s1 和 s2，分别说明对 s1 和 s2 表的访问方法是什么

### 15.1.2 id

查询语句一般都是以 SELECT 开头，有时一条查询语句中会出现多个 SELECT 关键字：

- 查询中包含子查询的情况，例如下面这条：

  ```sql
  select * from s1
  where key1 in (select key3 from s2);
  ```

- 查询中包含 UNION 子句情况，例如下面：

  ```sql
  select * from s1 union select * from s2;
  ```

查询语句中每出现一个 SELECT 关键字，就为它分配一个唯一 ID，这个 id 就是 EXPLAIN 输出的第一列。

对于连接查询来说，一个 SELECT 关键字后的 FROM 子句可以跟随多张表，连接查询的执行计划中，每个表都对应一条记录，但这些记录的 id 都相同，例如：

```sql
explain select * from s1 inner join s2;
```

![image-20220517143743105](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220517143743105.png)

上述连接查询中，参与连接的 s1 和 s2 表分别对应一条记录，但是这两条记录的 id 都是 1。

在连接查询的执行计划中，每个表都会对应一条记录，这些记录的 id 列的值是相同的，出现在前面的表表示驱动表，出现在后面的表表示被驱动表。

对于包含子查询的查询语句来说，可能涉及多个 SELECT 关键字，所以在包含子查询的查询语句执行计划中，每个 SELECT 都会对应一个唯一的 ID。

```sql
explain select * from s1 
where key1 in (select key1 from s2) or key3 = 'a'';
```

![image-20220517143720013](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220517143720013.png)

可以看到 s1 在外层查询中，外层查询中有一个独立的 SELECT 关键字，所以第一条记录的 id 就是1，s2 在子查询中，子查询有一个独立的 select 关键字，所以第二条记录的 id 就是 2

这里需要注意，查询优化器可能对涉及子查询的查询语句进行重写，进而转换为连接查询（半连接），例如：

```sql
explain select * from s1 
where key1 in (select key1 from s2);
```

![image-20220517144035964](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220517144035964.png)

对于包含 UNION 子句的查询语句来说，还有点特别的东西，例如：

```sql
explain select * from s1 union select * from s2;
```

![image-20220517144333575](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220517144333575.png)

这里的第三行多出了一个 id 为 null 的查询结果，并且 table 为 `<union1, 2>`

UNION 子句的作用是将多个查询的结果集合并起来并对结果集中的记录去重，如何去重呢？MySQL 使用的是内部临时表，正如上面的查询计划中，UNION 子句为了把 id 为 1 的查询和 id 为 2 的查询的结果集合并起来去重，在内部创建了一个名为 `<union1. 2>` 的临时表，id 为 null 表明这个临时表是为了合并两个查询的结果集而创建的。

与 Union 相比，UNION ALL 就不需要创建临时表，因为它根本不用去重，只是单纯把多个查询结果集中的记录合并成一个并返回给用户，所以就不需要临时表。

### 15.1.3 select_type

MySQL 设计者为每一个 SELECT 关键字代表的小查询都定义了一个名为 `select_type` 的属性，只要知道了某个小查询的 `select_type` 属性，就知道这个小查询在大查询中扮演的角色。

这里不细说了，感兴趣可以去看文档或者《MySQL 如何运行的》 p249-252

### 15.1.4 type

type 可以表明访问方法是啥，例如查询：

```sql
explain select * from s1 where key1 = 'a';
```

![image-20220517150625185](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220517150625185.png)

完整的访问方法有：system、const、eq_ref、ref、fulltext、ref_or_null、index_merge、unique_subquery、index_subquery、index、ALL等

- system：表中只有一条记录且该表使用的存储引擎的统计数据都是精确的，进行查询那么它的 `type` 就是 `system`

- `const`：根据主键或者唯一二级索引与常数进行等值匹配。

- `eq_ref`：执行连接查询时，如果被驱动表是通过主键或者不允许存储 NULL 值的唯一二级索引列等值匹配的方式进行访问的，对该被驱动表的访问方法就是 `eq_ref`，例如：

  ```sql
  explain select * from s1 inner join s2 on s1.id = s2.id;
  ```

  ![image-20220517151630637](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220517151630637.png)

- `ref`：通过普通二级索引与常量等值匹配查询，对该表的访问方法就是 ref；

  ```sql
  explain select * from s1 inner join s2 
  on s1.key1 = s2.key1;
  ```

  ![image-20220517151836123](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220517151836123.png)

- `fulltext`：全文索引

- `ref_or_null`：对普通二级索引进行等值匹配且该索引列的值也可以为 null 时，对该表的访问方法可能就是 `ref_or_null`

  ```sql
  explain select * from s1
  where key1 = 'a' or key1 is null;
  ```

- `index_merge`：一般情况下只会为单个索引生成扫描区间，但是某些场景下可以使用索引合并来执行查询。

  ```sql
  explain select * from s1
  where key1 = 'a' or key3 = 'a';
  ```

- `unique_subquery`：类似于两表连接中被驱动表的 `eq_ref` 访问方法，针对是一些包含 IN 子查询的查询语句，如果优化器决定将 IN 子查询转换为 EXISTS 子查询，且子查询转换后可以使用主键或者不允许 NULL 值的唯一二级索引进行等值匹配，那么该子查询的 type 列的值就是 `unique_subquery`

  ```sql
  explain select * from s1 where common_field in 
  (select id from s2 
   where s1.common_field = s2.common_field) 
  or key3 = 'a';
  ```

  ![image-20220517153255010](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220517153255010.png)

- `range`：索引获取某些单点扫描区间的记录，那么可能使用到 range 方法

  例如：

  ```sql
  explain select * from s1 where key1 in ('a', 'b', 'c');
  ```

- `index`：使用覆盖索引，扫描全部索引记录时，该表的访问方法就是 index，例如：

  ```sql
  explain select key_part2 from single_table 
  where key_part3 = 'a';
  ```

  ![image-20220517153619669](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220517153619669.png)

  另外比较特殊的一点，对于 `InnoDB` 来说，执行全表扫描，且要对主键进行排序，此时的 type 列的值也是 index，如下：

  ```sql
  explain select * from s1 order by id;
  ```

- ALL：全表扫描

### 15.1.5 `possible_keys` 与 `key`

`possible_keys` 是可能用到的索引有哪些，`key` 是实际用到的索引有哪些。

`possible_keys` 中的列不是越多越好，可以使用的索引越多，优化器在计算查询成本时花费的时间就越长，尽量删除用不到的索引。

### 15.1.6 `key_len`

```sql
explain select * from s1 where key1 > 'a' ANd key1 < 'z';
```

![image-20220517155828718](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220517155828718.png)

这里的 `key_len` 是 303，那么这个数值怎么来呢？

MySQL 设计者认为边界条件中包含的列都维护了一个 `key_len` 值，该 `key_len` 由下面 3 部分组成：

- 该列的实际数据最多占用的存储空间。例如 INT 类型的列，实际数据最多占用的存储空间就是 4 字节。如果用 utf8 字符集，类型为 `VARCHAR(100)` 的列来说，实际数据最多占：3 x 100 = 300 字节
- 如果该列可以存储 null 值，则 `key_len` 的值还要加 1
- 对于使用边长类型的列来说，会有 2 字节空间存储该列的实际占用存储空间长度，`key_len` 还要加 2

所以 300 + 1 + 2 = 303

### 15.1.7 filtered

- 如果使用全表扫描方式执行单表查询，那么计算驱动表扇出时需要估计出满足全部搜索条件的记录到底有多少条
- 如果使用索引来执行单表扫描，那么计算驱动表扇出时需要估计出在满足形成索引扫描区间的搜索条件外，还满足其他搜索条件的记录有多少条

```sql
explain select * from s1 where key1 > 'z' AND common_field = 'a';
```

使用 idx_key1 作为索引执行查询，条件 `key1 > 'z'` 用来形成扫描区间，从 row 可以看出满足 `key1 > 'z'` 的有 266条，这里 filtered 的值为 10.00，说明查询优化器预测：在 266 条记录中有 10% 的记录满足 `common_field = 'a'` 的条件。

如果是多表查询，例如：

```sql
explain select * from s1 inner join s2 
on s1.key1 = s2.key1 where s1.common_field = 'a';
```

![image-20220517162449359](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220517162449359.png)

对 s1 表的 filtered 为 10.00，说明 9688 条记录中只留下了 10%，也就是说要对 s2 做 968 次 查询。

### 15.1.8 Extra

Extra 可以给定一些额外的信息，这里挑几个重要的：

- Using index：使用覆盖索引查询，不需要回表。

- Using index condition：有些搜索条件虽然出现了索引列，但不能充当边界条件，也就说不能减少需要扫描的记录数，例如：

  ```sql
  explain select * from s1
  where key1 > 'z' and key1 like '%a';
  ```

  这里的意思就是 **索引下推**

  > 索引下推：
  >
  > 以前 MySQL 执行查询的时候例如有条件 key1 > 'z'，那么 MySQL 在二级索引查询一条 key1 > 'z' 的记录则立刻回表判断其他条件是否成立，如果成立则返回否则回到二级索引继续遍历。
  >
  > 有了索引下推后 MySQL 在二级索引查询的时候就会尽可能进行其他的查询，例如这里的 key1 like '%a'，如果不满足就不回表了。

- Using where：某个搜索条件需要在 server 层判断，例如：

  ```sql
  explain select * from s1 
  where key1 >'a' and common_field = 'a';
  ```

  这里对于 `common_field `不能使用索引下推，必须回表才能判断。

  ![image-20220517163535829](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220517163535829.png)

- Using filesort：对结果集中的记录进行排序，但是排序的列很多或者它不是索引，则只能在磁盘中（记录多）或者内存中（记录少）进行排序，这样的话统称为 文件排序（filesort）。

# 十七章. `InnoDB` 的 Buffer Pool

## 17.1 缓存的重要性

对于 `InnoDB` 存储引擎来说，无论是用于存储用户数据的索引，还是各种系统数据，都是以页的形式放在表空间，物理上来说还是放在磁盘中，由于磁盘速度很慢，所以 `InnoDB` 存储引擎在处理客户端请求时，如果需要访问某个页的数据，会把完整页的数据全部加载到内存，之后就可以进行读写访问了，且读写访问后不用立刻把对应的内存空间释放，而是将其缓存起来，这样再次访问页面就可以省下 IO 开销了。

## 17.2 `InnoDB` 的 Buffer Pool

### 17.2.1 什么是 Buffer Pool

为了缓存磁盘中的页，`InnoDB` 设计者在 MySQL 服务器启动时就向 OS 申请了一片连续的内存，也就是缓冲池，默认 `Buffer Pool` 大小为 128MB，可以在启动服务器时候配置 `innodb_buffer_pool_size` 启动选项，例如：

```
[server]
innodb_buffer_pool_size = 268435456
```

这里的单位是字节，最小是 5MB

### 17.2.2 Buffer Pool 内部组成

Buffer Pool 对应的一片连续内存被划分为若干个**页面**，页面大小与 `InnoDB` 表空间使用的页面大小一致，默认都是 16KB，这里我们称之为缓冲页。

为了更好管理这些缓冲页，每一个缓冲页都创建了一些控制信息，包括该页所属的表空间编号，页号，缓冲页在 Buffer Pool 的地址，链表节点信息等。

每个缓冲页对应的控制信息占用的内存大小相同，我们把每个页对应的控制信息占用的一块内存称为一个控制块。控制块和缓冲页是一一对应的，都存放在 Buffer Pool 中。控制块放在 Buffer Pool 的最前面，缓冲页放在 Buffer Pool 的最后面。



![image-20220518094957036](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220518094957036.png)

其中使用不到的内存空间就是碎片。

### 17.2.3 free 链表的管理

我们最初启动 MySQL 时，需要完成 Buffer Pool 的初始化，先向 OS 申请 Buffer Pool 的内存空间，将它划分为控制块和缓冲页，但是没有真正的磁盘也被缓存到 Buffer Pool 中，随着程序的运行，会不断有磁盘页刷新到缓冲页中。

问题：从磁盘上读取一个页到 Buffer Pool 应该放在那个缓冲页位置呢？

答：在控制块记录哪些缓冲页可用，我们可以将所有空闲的缓冲页对应的控制块作为一个节点放到一个链表中，这个链表可以称为 free 链表。

刚刚初始化的 Buffer Pool，所有的缓冲页都是空闲的，因此每一个缓冲页对应的控制块都在 free 链表中。假设有 n 张缓冲页：

![image-20220518100219581](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220518100219581.png)

free 链表是一个双端链表，存在基节点，存储第一个、最后一个控制块的地址，与链表中控制块的数量。

有了 free 链表就好办了，当需要从磁盘中加载一个页到 Buffer Pool 中时，就从 free 链表取一个空闲的缓冲页，并且把缓冲页对应的控制块信息填上，然后将缓冲页对应的 free 链表节点从链表中移除，表示该缓冲页已经被使用了。

### 17.2.4 缓冲页的哈希处理

当我们要访问某个页的数据时，就会将该页从磁盘加载到 `Buffer Pool` 中，如果改页已经在 Buffer Pool 中，直接使用即可。

问题：如何直到该页在不在 Buffer Pool 中？

答：根据 表空间号 + 页号，如果知道了这两个条件，那么一个页就可以确定了，这就构成了一个键值对 `<key, value>`，key 是表空间号 + 页号，value 是对应的缓冲页地址。

### 17.2.5 flush 链表的管理

如果我们修改了 Buffer Pool 中某个缓冲页数据，就存在缓存与磁盘上的页不一致了，这样的缓冲页称为脏页。

问：如何处理脏缓冲页？

答：使用 flush 链表。每当修改完某个缓冲页是，如果立即刷新到磁盘页，会影响程序的性能，但是如果不立即修改刷新到磁盘，之后再刷新我们怎么知道哪些页是脏页呢？

我们创建一个存储脏页的链表，凡是被修改过的缓冲页对应的控制块都会作为一个节点加入这个链表中，如下图：

![image-20220518104106011](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220518104106011.png)

### 17.2.6 LRU 链表的管理

#### 缓冲区不够

Buffer Pool 对应的大小是有限的，如果缓存的页占用的内存大小超过了 Buffer Pool 的大小，那就要把旧的缓冲区从 Buffer Pool 中移除，然后将新的页放进来，问题来了，移除哪些缓冲页呢？

设计 Buffer Pool 的初衷就是减少磁盘IO，最好每次访问某页时它就已经在磁盘中了，假设我们一共访问了 n 次页，那么被访问页已经在 Buffer Pool 的次数 / n 就是命中率，我们期望命中率越高越好，从这个角度，留下最近很频繁使用的页就好了。

#### 简单的 LRU 链表

要完成这样的任务，当然要依靠 LRU（Least Recently Used）链表，需要访问某个页，可以按照这样的方式处理：

- 该页不在 Buffer Pool 中，该页从磁盘加载到缓冲页，把控制块作为节点塞到 LRU 链表的头部。
- 该页在 Buffer Pool 中，直接把该页对应的控制块移动到 LRU 链表头部。

#### 划分区域的 LRU 链表

上面这个简单的 LRU 链表容易出问题

- `InnoDB` 提供一个贴心的服务：预读。`InnoDB` 读取某个页时，可能会在后面读取某些页时预先将这些页面加载到 Buffer Pool 中去。预读又分为以下两种：

  - 线性预读：

    读取一个页面时可能会将它的下一个页面也异步读取到 Buffer Pool 中去。

  - 随机预读：

    如果某个区的 13 个连续页面都被加载到 Buffer Pool 中，会触发一次异步读取本区中所有其他页面到 Buffer Pool 中。

  预读本来是好事，如果预读到 Buffer Pool 中的缓存页被用到就可以大大优化效率，但是如果用不到就会占据 Buffer Pool 的容量造成浪费和性能下降。

- 执行全表扫描。

  全表扫描意味着访问该表的聚簇索引的所有叶子节点对应的页，如果需要访问的页面特别多，而 Buffer Pool 又不能全部容纳它，这就意味着需要将其他语句执行过程中的页面挤出 Buffer Pool，这就严重影响了 Buffer Pool 的效率。

因为这两种情况的存在，`InnoDB` 的设计者将这个 LRU 链表按照一定比例分成两部分：

- 热数据（young 区域）：使用频率很高的数据
- 冷数据（old 区域）：使用频率低的数据

![image-20220518141132856](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220518141132856.png)

我们按照某个比例将 LRU 链表分为两部分，不是某些节点固定位于某个区，按照程序运行某个节点所属的区域也可能发生变化。这个比例可能通过

```mysql
show variables like 'innodb_old_blocks_pct';
```

查看，显示的是 old 区占总 LRU 链表的大小，默认是 37%，也就是 3/8

![image-20220518141605518](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220518141605518.png)

有了这个设定后，`InnoDB` 设计者就可以针对前面提到的两种可能降低 `Buffer Pool` 命中率的情况进行优化了。

- 针对预读的页面可能不进行后续访问的优化。

  `InnoDB` 设计者规定，当磁盘上某个页面初次加载到 Buffer Pool 中的某个缓冲页时，该缓冲页对应的控制块会放到 old 区域的头部，这样，预读到 Buffer Pool 却不进行后续访问的页面就会被逐渐从 old 区域逐出，而不会影响 young 区域的缓冲页。

- 针对全表扫描时

  虽然首次加载到 Buffer Pool 中的页放到了 old 区域的头部，但是后续会被马上访问到，每次进行访问时又会将改页放到 young 区域的头部，这样仍会把使用频率较高的页面给挤下去。

  因为当访问一个记录时，它的页就相当于多访问了一次，由于是全表扫描，全部记录都会被访问一遍，因此每张数据页会被访问多次。

  那怎么办呢？全表扫描有一个特点，就是它的执行频率很低，而且在执行全表扫描时，即使某个页面有很多条记录，每读取一条记录都算访问一次页面，但是这个过程花费的时间是很少的。所以我们只需规定：**在对某个处于 old 区域的缓冲页进行第一次访问时，就在它对应的控制块中记录下这个访问时间，如果后续的访问时间和第一次访问时间在某个间隔内，该页面就不会从 old 区转移到 young 区**。这个间隔时间由 `innodb_old_blocks_time` 控制，默认 1000，单位是 ms。

  ![image-20220518145252241](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220518145252241.png)

  如果设置为 0，那么每访问一次页面就将该页面放到 young 区域头部。

#### 进一步优化 LRU 链表

对于 young 区域，我们每次访问一个缓冲页就要将它移动到 LRU 头部，这样开销是否有点大，毕竟 young 区域是热点数据，这样频繁对 young 区域进行节点移动是不是有点耗费性能。

为了解决这个问题，还可以提出一些优化策略，例如只有被访问的缓冲页位于 young 区域 1/4 的后面，才会被移动到 LRU 头部，这样可以降低调整 LRU 链表的频率。

![image-20220518145835098](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220518145835098.png)

### 17.2.8 刷新脏页到磁盘

后台有专门的线程负责每隔一段时间就将脏页刷新到磁盘，这样可以不影响用户线程处理正常请求，刷新方式主要有下面两种：

- 从 LRU 链表的冷数据中刷新一部分页面到磁盘

  后台线程定时从 LRU 链表尾部开始扫描一些页面，扫描的页面数量可以通过系统变量 `innodb_lru_scan_depth` 指定，如果在 LRU 中发现脏页，将其刷新到磁盘。

- 从 flush 链表中刷新一部分页面到磁盘

  后台线程也会定时从 flush 链表刷新一部分页面到磁盘，取决于当时系统是否繁忙。

有时，后台线程刷新脏页速度太慢了，导致用户线程加载缓冲页时发现没地方了，这时会尝试查看 LRU 尾部，看是否存在可以直接释放的未修改缓冲页，如果没有，不得不将 LRU 尾部的一个脏页同步刷新到磁盘。

# 十八章. 事务

## 18.1 事务四大特性：

**原子性（Atomicity）**

> 例如说一个事务中有若干条命令，那么这些命令要么全执行，要么全都不执行。

**隔离性（Isolation）**

> 两个事务读取的变量状态应该是相互隔离的，事务 A 运行时的变量 x 事务 B 无法读取到。
>
> 例如有一个业务，A 向 B 转账 5 元，由下面几个步骤组成：
>
> - 读取余额到变量 x 中，read(x)
> - 将 A 账户余额将去转账金额。 x -= 5
> - 余额写入到 x 中，write(x)
> - 将 B 账户余额读入到 y 中。read(y)
> - 将 y 加上转账金额。y += 5
> - 将 y 写入 B 账户余额。write(y)
>
> 由于这里是一个事务，因此如果要发生两次转账的话那么这两个事务只能互斥，即只有一个事务运行完成另一个事务才可以运行。

**一致性（Consistency）**

> 事务前后进行操作时要保证一致性，例如转账动作，一个账户向另一个账户转账 x 元，事务前后有几个状态不能改变：
>
> - 两个账户余额加起来不能改变（没有其他账户对某个账户进行转账的话）。
> - 两个账户余额不能为负。

**持久性（Durability）**

> 当一个状态转换完成，这个转换的结果将被永久保留，这个规则就是持久性。

## 18.2 事务概念

事务的几个状态：

- **活动的**：事务对应的数据库正在执行过程中。
- **部分提交的**：事务中最后一个操作执行完成，但由于操作都在内存中执行，并没有刷新到磁盘中。
- **失败的**：事务处于活动状态或者部分提交时无法继续执行，或者人为停止事务执行。
- **中止的**：事务执行了半截而变为失败的状态，那么就要撤销失败事务前对数据库造成的影响，也就是回滚。回滚执行完毕，数据库恢复到执行事务前的状态，该事务处于中止状态。
- **提交的**：处于部分提交状态的事务将修改过的数据都刷新到磁盘中后。

![image-20220603155501018](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220603155501018.png)

# 十九章. redo 日志

## 19.1 redo 日志是啥

由事务的持久性我们知道，当一个事务提交后，我们要确保这个事务对数据库的影响要一直存在，也就是持久化到磁盘。

但是 MySQL 的原理是将页加载到内存中，在内存中进行操作，如果事务完成后 MySQL 崩溃了，内存中的数据没有及时刷新到磁盘，就会出现数据丢失，也就无法确保持久性了。

redo 日志就可以确保事务的持久性，我们修改页面中的数据时不用立即刷新页回磁盘，我们只需要记录一下就好，例如某个事务将系统表空间100号页面偏移量为 1,000 处的字节的值从 1 修改为 2，我们只需要记录：

```
将 0 号表空间第 100 号页面中偏移量为 1000 处的值更新为 2
```

这样事务提交后就会把上述内容刷新回磁盘，即使之后系统崩溃了，重启只要按上述内容的记录重新更新一下数据页，该事务对数据库中所做的修改就可以恢复出来，这样也就满足持久性的要求了。

redo 日志好处：

- 占用空间小。
- 按顺序写入磁盘，可以使用顺序 IO

## 19.2 redo 日志格式

![image-20220605155236896](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220605155236896.png)

- **type**：这条 redo 日志的格式
- **space ID**：表空间 ID
- **page number**：页号
- **data**：redo 日志的具体内容

redo 日志会把事务执行过程中对数据库的修改都记录下来，之后系统因崩溃而重启后可以将事务所做的任何修改都恢复过来。

## 19.3 Mini-Transaction

### 19.3.1 以组的形式写入 redo 日志

例如我们在事务中要向表中插入一条记录，那么可能要更新多个页，例如数据页，索引页等，对于不同种类的页我们可以对其分组。插入这条记录前，我们需要先定位到具体的数据页，这是有两种可能的情况：

- **该数据页剩余的空间充足，足够容纳一条待插入记录**，这样直接插入即可，这被称为**乐观插入**。
- **该数据页剩余的空间不足，需要进行页分裂操作**，这样就要生成很多 redo 日志。这种被称为**悲观插入**。

为了防止悲观插入时出现系统崩溃，导致 redo 日志写入的不完整，所以 InnoDB 设计者规定执行向 B+ 树插入一条记录时必须是原子性的操作，因此在记录 redo 日志时必须按组记录 redo 日志，要么都执行，要么都不执行，那么如何做到呢？

- 需要保证原子性操作会生成多条 redo 日志，例如向某个索引对应的 B+ 树中进行一次悲观插入，就要生成多条 redo 日志。

  InnoDB 设计者是这样设计的：在该组中的最后一条 redo 日志后面加上一条类型特殊的 redo 日志，只有一个 type 字段。

  这样在系统崩溃恢复时，只有解析到这条特殊的 redo 日志时，才会进行恢复，否则放弃之前解析到的 redo 日志。

- 有些需要保证原子性操作的只生成一条 redo 日志，那么就可以在 type 处标记这组 redo 日志只有这一条。

### 19.3.2 Mini-Transaction 的概念

将对底层页面进行一次原子访问的过程称为一个 Mini-Transaction，悲观插入和乐观插入都是一次 MTR，我们可以知道一个 MTR 可以包含一组 redo 日志，也可以只包含一条 redo 日志。

![image-20220605163327339](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220605163327339.png)

## 19.4 redo 日志的写入过程

### 19.4.1 redo log block

通过 MTR 生成的 redo 日志都放在了大小为 512 字节的页中，用来存储 redo 日志的页被称为 block。

### 19.4.2 redo 日志缓冲区

写入 redo 日志时不能直接写入到磁盘中，实际上服务器启动时就向 OS 申请了一大片被称为 redo log buffer（redo 日志缓冲区）的连续内存空间。

可以通过启动选项 `innodb_log_buffer_size` 来指定 log buffer 大小，默认值为 16MB

### 19.4.3 redo 日志写入 log buffer

顺序写入，先往前面的 block 中写入，写完后向下一个 block 写入，InnoDB 设计者提供了一个 `buf_free` 全局变量，指明后续写入的 redo 日志应该写入到 log buffer 中的哪个位置。如下图：

<img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220605165920989.png" alt="image-20220605165920989" style="zoom:67%;" />

每次写入时不是每生成一条 redo 日志就立即写入，而是以 MTR 为单位进行写入。

## 19.5 redo 日志文件

### 19.5.1 redo 日志刷盘时机

一些情况下 redo 日志会被刷新到磁盘：

- log buffer 空间不足时。如果 log buffer 中的 redo 日志量已经占满了 log buffer 总容量的 50% 左右，就将这些日志刷新到磁盘中。
- 事务提交时。为了保证持久性，需要将 redo 日志刷新回磁盘。
- 某个脏页刷新到磁盘前，会保证该脏页对应的 redo 日志刷新回磁盘中。
- 后台有一个线程，每秒一次刷新到磁盘。
- 正常关闭服务器。
- check point 时

### 19.5.2 redo 日志文件组

redo 日志在磁盘上是以日志文件组的形式出现，如下图：

![image-20220605171212725](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220605171212725.png)

它是一个循环文件的标志出现，即如果写到了最后，那么重新从头开始写。

但是这样可能导致后写入的 redo 日志覆盖之前写过的 redo 日志文件格式，所以 InnoDB 设计者提出了 check point 概念。

## 19.6 log sequence number

系统开始运行时就在不断修改页面，意味着不断生成 redo 日志，redo 日志的量在不断增加，MySQL 通过一个名为 lsn（log sequence number）来维护 redo 日志的总量，从 8,704 开始，如果写了 200 字节的 redo 日志，那么 lsn 就变味 8,904

每个 MTR 生成的 redo 日志都有一个唯一的 lsn 值对应，lsn 越小，redo 日志产生的越早，lsn 越大，redo 日志产生的越晚。

## 19.7 check point

redo 日志文件组的容量有限，我们选择循环使用 redo 日志文件组中的文件，但是会造成后写入的 redo 日志与最开始写入的 redo 日志覆盖。

但是 redo 日志只是为了在系统崩溃后恢复脏页使用，如果对应的脏页刷新到磁盘了，重启后也可以不用 redo 日志恢复该页面，所以该 redo 日志就没有存在的必要了。那么只要我们判断脏页刷新回了磁盘，就可以释放这个脏页有关的 redo 日志内容。

InnoDB 设计者提出了一个全局变量 `checkpoint_lsn`，用来表示当前系统中可以被覆盖的 redo 日志总量是多少，这个变量初始值是 8,704

例如 MTR_1 对应的脏页是 a，如果 a 刷新回了磁盘，那么 MTR_1 生成的 redo 日志就可以被覆盖了，可以进行一个增加 `checkpoint_lsn` 的操作，我们将这个操作称为 check point。

check point 可以分为两个步骤：

- 计算当前系统中可以被覆盖的 redo 日志对应的 lsn 值最大是多少，redo 日志可以被覆盖，这意味着对应的脏页被刷新回了磁盘，只要我们计算出当前系统中最早修改的脏页对应的 `oldest_modification` 值，凡是系统在 lsn 值小于该节点的 `oldest_modification` 值时产生的 redo 日志都可以被覆盖掉。我们将该脏页的 `oldest_modification` 赋值给 `checkpoint_lsn`
- 将 `checkpoint_lsn` 对应的 redo 日志文件组偏移量以及此次 check point 的编号写入到日志文件的管理信息。

## 19.8 崩溃恢复

服务器不挂的时候，redo 日志是没有用且耗费性能的，但是一旦数据库挂了，redo 日志就有大用了。

### 19.8.1 确定恢复的起点

对于 lsn 值不小于 `checkpoint_lsn` 的 redo 日志，它们对应的脏页可能没被刷盘，也可能被刷盘了，我们不能确定，所以要从 `checkpoint_lsn` 开始恢复页面。

### 19.8.2 确定恢复的终点

由于 redo 日志是顺序写入的，因此恢复的终点就是 redo 日志的终点。

### 19.8.3 怎么恢复

假设 redo 日志文件中有 5 条 redo 日志：

![image-20220605182307750](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220605182307750.png)

- 使用哈希表

  根据 redo 日志的 `space ID` 和 `pagenumber` 属性计算出哈希值，将相同的 redo 日志放到哈希表的同一个槽中，如果有多个 space ID 和 page number 都相同的 redo日志，说明它们是同一页，那么只要更新一次即可，这样就可以大大节省效率。

- 跳过已经刷新到磁盘中的页面

  对于 lsn 大于 `checkpoint_lsn` 的页面无法确保到底是不是已经刷新到磁盘中，因为执行 check point 时后台线程可能不断从 LRU 链表和 Flush 链表中将脏页刷出 Buffer pool。对于 lsn 值大于 `checkpoint_lsn` 的 redo 日志，如果他们对应的脏页在崩溃时已经刷新到磁盘，那就没有必要再执行 redo 日志了。

  那么怎么知道有没有刷新过呢？通过页面的头部有一个 `FIL_PAGE_LSN` 的属性，记载了最近一次修改页面时对应的 lsn 值，执行了 checkpoint 后该页被刷新到磁盘中，该页对应的 `FIL_PAGE_LSN` 肯定大于 `checkpoint_lsn` 的值，因此就不需要执行 redo 日志了。

# 二十章. undo 日志

## 20.1 事务回滚

由于事务的原子性：要么全做，要么什么都不做。有时事务执行到一般会出现一些错误，这就需要我们回滚事务，使这个事务什么都不做，返回到事务开始前的状态。

当我们对一条记录进行该董事，都需要将回滚时需要的东西记录下来，例如：

- 插入一条记录，要把这条记录的主键值记录，这样回滚时只要将这个主键值对应的记录删除即可。
- 删除一条记录，要把这条记录的内容记录下来，回滚时将这条记录插入到表中即可。
- 修改记录时要把被更新的列及其旧值记录下来，回滚时将这些列更新为旧值即可。

查询操作执行时不用记录 undo 日志，因为不会造成数据库的记录产生任何影响。

## 20.2 事务 id

如果某个事务在执行过程中对表执行了增删改操作，InnoDB 就会给它分配一个独一无二的事务 ID。

- 服务器在内存中会维护一个全局变量，每当需要为某个事务分配事务 id 时，会将该变量的值作为事务 id 分配给当前事务，自增该变量。
- 这个变量的值为 256 的倍数时，会将该变量的值刷新到系统表空间的一个固定页面中。
- 当系统下一次重启时会将这个变量值加载到内存中，将该值加上 256 止呕后赋值给前面提过的全局变量。

这样可以保证事务 id 大的是后开启的事务，事务 id 小的是先开启的事务。

## 20.3 undo 日志格式

undo 日志会从 0 开始编号，根据生成的顺序生成 0 号 undo 日志、1 号 undo 日志...这个编号也称为 undo no。

### 20.3.1 INSERT 操作对应的 undo 日志

虽然插入有乐观插入和悲观插入，但是最终导致的结果都相同，就是一条记录被放入了一个数据页中，如果希望回滚这个插入操作，那就删除这条记录即可。所以 InnoDB 设计者设计了类型为 `TRX_UNDO_INSERT_REC` 的 undo 日志，它的结构如下：

![image-20220606151353943](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220606151353943.png)

> 我们向表中插入记录时实际上需要更新聚簇索引和二级索引，不过记录 undo 时，只需要针对聚簇索引记录即可，聚簇索引和二级索引是一一对应的，我们回滚 INSERT 时，只需知道这条记录的主键信息，根据主键进行对应的删除操作。

### 20.3.2 DELETE 操作对应的 undo 日志

数据页中被删除的记录会加入垃圾链表，我们在删除一条记录时，会分两步执行：

- 标记这条记录为垃圾记录，其他不做修改。
- 删除语句事务提交后，专门的线程来真正将这条记录删除掉，也就是将这条记录从正常记录链表移除，加入到垃圾链表中，然后调整页面其他信息。

InnoDB 设计者为此设计了一种名为 `TRX_UNDO_DEL_MARK_REC` 类型的 undo 日志

<img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220606153554495.png" alt="image-20220606153554495" style="zoom:67%;" />

###  20.3.3 UPDATE 操作对应的 undo 日志

对于更新与不更新的主键操作是不同的。

#### 不更新主键

又可以细分为更新后的列占用的存储空间是否发生变化。

- 就地更新

  存储空间发生的变化不大，可以就地更新，直接在原记录的基础上修改对应的值即可。

- 先删除旧记录，再插入新记录

  如果更新前后占用的存储空间大小不一，需要删除旧记录，然后插入新记录，这里的删除不是上面的删除，而是真正删除，也就是移动到垃圾链表中。

![image-20220606162657693](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220606162657693.png)

#### 更新主键

聚簇索引中，记录按照主键值的大小连接成一个单向链表，如果我们更新了某条记录主键值，意味着这条记录在聚簇索引中的位置要发生改变，针对这种情况，InnoDB 分两步处理：

- 旧记录进行 `delete mark` 操作，也就是标志这条记录为被删除记录，但是没有加入到垃圾链表中。放入到垃圾链表这个操作由后台线程完成。
- 根据更新后各列的值创建新纪录，插入到聚簇索引中。

![image-20220606162719922](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220606162719922.png)

### 20.3.4 增删改操作对二级索引的影响

如果我们修改了某条记录，那么可能会影响到索引列，所以要修改对应的二级索引记录，要进行如下操作：

- 对旧的二级索引记录执行 delete mark 操作，不是彻底删除，主要是考虑 MVCC
- 根据更新后的值创建新的二级索引记录，在对应的 B+ 树重新定位位置并插入

## 20.4 `FIL_PAGE_UNDO_LOG` 页面（undo 页面）与 Undo 页面链表

### 20.4.1 undo 页面

`FIL_PAGE_UNDO_LOG` 这种类型的页面是专门用来存储 undo 日志的，这种类型的页面的通用结构如下图：

![image-20220606163234272](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220606163234272.png)

其中 `Undo Page Header` undo 页面头用来标记本页面用于存储哪个大类的 undo 日志，不同大类的 undo 日志不能混着存储。

### 20.4.2 undo 页面链表

#### 单个事务的 undo 页面链表

在对普通表和临时表的记录改动时产生的 undo 日志会分别记录，而且不同类型的 undo 页面（两种，insert 和 update）也会分别记录，所以一个事务最多有 4 中不同的 undo 页面（普通表和临时表，insert 和 update）

![image-20220606164028176](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220606164028176.png)

#### 多个事务的 undo 页面链表

![image-20220606164124317](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220606164124317.png)

不是事务一开始就为它分配 4 条链表，而是按需分配，需要则分配，不需要不分配。

## 20.5 undo 日志写入过程

### 20.5.1 Undo Log Segment Header(Undo 页面段)

InnoDB 设计者规定，每个 Undo 页面链表都对应着一个段，链表中的页面就是从这个段中申请的，他们在 Undo 页面链表的第一个页面设计了 `Undo Log Segment Header` 部分，这个部分包含了链表对应段的 `Segment Header` 信息。如下图：

![image-20220606165029118](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220606165029118.png)

而 Undo 页面写入则是直接堆砌即可。

## 20.6 重用 Undo 页面

为了提高并发执行的多个事务写入 undo 日志的性能，InnoDB 设计者决定为每个事务单独分配相应的 Undo 页面链表，但是问题是一个事务可能只修改一条或几条数据，即产生了非常少的 undo 日志，这些 undo 日志可能只占用一点点存储空间，我们也要为其创建一个 undo 页面链表，这样会造成性能浪费。

为了节约这部分内存空间，InnoDB 设计者决定事务提交后某些情况下重用该事务的 Undo 页面链表，一个 Undo 页面链表如果可以被重用，那么它只需要符合以下两个条件：

- 该链表只包含一个 undo 页面
- 该 undo 页面已经使用的空间小于整个页面空间的 3/4

而对于不同的 undo 链表也有不同的优化方案

- insert undo 链表

  事务提交后，这种类型的 undo 日志没有用了，重用此页面的话可以直接覆盖。

- update undo 链表

  为了实现 MVCC，它的 undo 日志不能立即删除，所以不能覆盖之前的 undo 日志，需要在后面写。

# 二十一章. 事务隔离级别和 MVCC

## 21.1 准备

创建一张表

```sql
create table hero {
	number INT,
	name varchar(100),
	country varchar(100),
	primary key (number)
} Engine=InnoDB CHARSET=utf8;
```

插入一条记录：

```sql
insert into hero values(1, '刘备', '蜀');
```

## 21.2 事务隔离级别

两个并发事务执行时可能产生的问题：

例如我们开启两个相同的事务，A 向 B 转账 5 元钱，如果并发执行的不恰当可能出现以下情况：

![image-20220607153014209](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220607153014209.png)

我们明明执行了两次转账，但是 A 账户的余额只少了 5 元钱，B 账户的余额增加了 10 元，这时就出现不一致了。

> 两个并发事务在执行过程中访问相同的数据情况有 读-读、读-写、写-读、写-写 情况，其中 读-读 情况是可以忽略的，关键就是有写操作参与的事务需要同步控制，需要对操作进行排队（通常通过加锁实现）

### 21.2.1 事务并发执行遇到的一致性问题

- **脏写**

  一个事务修改了另一个未提交的事务修改过的数据。

- **脏读**

  一个事务读取了另一个未提交的事务修改过的数据。

- **不可重复读**

  一个事务修改了另一个未提交的事务读取的数据。

- **幻读**

  一个事务根据某些条件查出一些记录，事务未提交时，另一个事务写入了一些符合这些条件的记录，也就是发生了幻读。

### 21.2.2 SQL 标准中的 4 种隔离级别

- `read uncommitted`：读未提交
- `read committed`：读已提交
- `repeatable read`：可重复读
- `serializable`：可串行化

|      隔离级别      | 脏读 | 不可重复读 | 幻读 |
| :----------------: | :--: | :--------: | :--: |
| `read uncommitted` | :x:  |    :x:     | :x:  |
|  `read committed`  |  ✔   |    :x:     | :x:  |
| `repeatable read`  |  ✔   |     ✔      | :x:  |
|   `serializable`   |  ✔   |     ✔      |  ✔   |

无论哪种隔离级别都不允许脏写

### 21.2.3 MySQL 中支持的 4 中隔离级别

MySQL 支持的四种隔离级别和 SQL92 标准的隔离级别有出入—— MySQL 在 `repeatable read`（可重复读）级别下，很大程度上禁止幻读现象发生。MySQL 默认隔离级别为 `repeatable read`。

***设置事务隔离级别***

```sql
SET [GLOBAL|SESSION] TRANSACTION ISOLATION LEVEL level;
```

在 SET 后面可以放置 `GLOBAL、SESSION` 关键字或者什么都不放，会对不同范围的事务产生不同的影响。

- 使用 `GLOBAL` 关键词

  只对执行完该语句后新产生的会话起作用，当前存在的会话不起作用。

- 使用 `SESSION` 关键词

  对当前会话的所有后续事务有效，可以在已经开启的事务执行，不影响当前正在执行的事务，对后续的事务有效。

- 什么都不用

  只对当前会话中下一个即将开启的事务有效，下一个事务执行完后，后续事务将恢复到之前的隔离级别，该语句不能在已经开启的事务中执行，否则报错。

## 21.3 MVCC 原理

### 21.3.1 版本链

- trx_id：事务 id
- roll_pointer：版本链指针

版本链主要存储 update undo 日志的信息，而 insert undo 日志在事务提交后就可以清除了。

例如：

![image-20220607161953916](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220607161953916.png)

那么它的版本链就是：

![image-20220607162024679](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220607162024679.png)

事务 id 越大的记录（也就是越晚的事务），会在版本链的前端出现。

版本中还包含生成该版本时对应的事务 id，这个信息很重要，我们会利用这个记录的版本链来控制并发事务访问相同记录时的行为，我们将这种机制称为多版本并发控制（MVCC）。

### 21.3.2 Read View

不同隔离级别读取记录可能是不同的，读未提交读取的就是版本链头节点的数据，而读已提交和可重复读要求读的是提交的事务修改的记录。

那么如何判断版本链中哪个版本是当前事务可见的，为此，InnoDB 设计者提出了 `ReadView`（一致性视图）的概念，包含了 4 个重要信息：

- m_ids：系统中活跃的读写事务的事务 id 列表
- min_trx_id：系统中活跃的读写事务中的最小事务 id
- max_trx_id：系统应分配给下一个事务的事务 id 值
- creator_trx_id：生成该 Read View 的事务的事务 id

有了这个 read view 在访问某条记录时，只要按照下面步骤来判断记录的某个版本是否可见：

- trx_id == creator_trx_id：当前事务访问它自己修改过的记录，可以被当前事务访问
- trx_id < min_trx_id：当前事务已经被提交，可以被访问
- trx_id >= max_trx_id：当前事务没有提交，不能访问
- trx_id > min_trx_id && trx_id < max_trx_id：查看 trx_id 是否在 m_ids 中，如果在说明事务未提交，不能访问，否则可以访问

在 MySQL 中，读已提交和可重复读隔离级别的一个非常大的区别就是它们生成 Read View 的时机不同。

#### 读已提交— —每次读取数据前都生成一个 Read View



#### 可重复读— —第一次读取数据时生成一个 Read View

## 21.4 关于 purge

insert undo 日志在事务提交后可以释放，而 update undo 日志由于要支持 MVCC，因此不能立即删除。但是这些存储空间就一直存放这些 undo 日志吗，这样占据的空间太大了。

为了支持 MVCC，delete mark 操作仅仅是记录上打一个删除标记，没有真正将记录删除。这些被打了删除标记的记录会在合适的时候将 update undo 日志以及仅仅被标记为删除的记录彻底删除，这个删除就被称为 purge，问题在于 purge 操作何时执行。

update undo 日志和被标记为删除的记录仅仅是为了支持 MVCC 而存在的，只要系统中最早产生的 Read View 不再访问了，那么就可以删除了。
问题是 Read View 什么时候才肯定不会访问某个事务执行过程中产生的 undo 日志呢，只要我们能保证生成 ReadView 时某个事务已经提交了，那么该 Read View 就不需要访问该事务运行过程中产生的 undo 日志了。

InnoDB 设计者通过事务 no 来确定何时删除 Read View：

> 根据事务 no 的大小（越大越新）可以确定事务先后，而 Read View 内部也持有一个 事务 no
>
> InnoDB 中会维护系统当前活跃的 Read View 链表，执行 purge 操作（真正删除不用的 update undo 日志时）从回滚段中取出事务 no 值较小的各组 undo 日志，如果这组 undo 日志的事务 no 值小于当前系统最早生成的 Read View 的事务 no 属性值，意味着这组 undo 日志没用了，可以删了。
>
> 这里要注意，如果使用可重复读，每次都使用一个 Read View，如果这个事务迟迟不提交，那么就会造成 undo 日志堆积，影响性能。

# 二十二章. 锁

## 22.1 解决并发事务带来问题的两种基本方式

并发事务可以产生问题的情况分为两种：

- 写-写情况
- 读-写 或者 写-读 情况

### 22.1.1 写 - 写 情况

写-写 可能导致脏写，任何一种隔离级别都不允许这种情况发生，所以多个未提交事务对一条记录进行改动时需要排队执行，而排队就是通过加锁来实现。这个 "锁" 是一个内存中的结构。

事务执行前本来没有锁，一开始没有锁结构进行关联，当一个事务想对这条记录进行改动，首先会看内存中有没有与这条记录关联的锁结构，如果没有就生成。

<img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220608144925206.png" alt="image-20220608144925206" style="zoom:67%;" />

- trx 信息：这个锁结构与哪个事务关联。
- is_waiting：表示当前事务是否在等待。

事务改动这条记录前，生成一个锁结构与记录关联，因为此时没有别的事务为这条记录加锁，因此 `is_waiting` 是 false，这个场景称为获取锁成功，或者加锁成功，可以继续执行操作。

事务 T1 提交前，另一个事务 T2 想对该记录进行改动，T2 先查看有没有锁结构与这条记录关联，发现有 T1 了，T2 也生成一个锁结构与这条记录关联，不过 `is_waiting` 属性值为 true，表示需要等待，这个场景称为获取锁失败，或者加锁失败。

T1 提交后，会释放它生成的锁结构，然后检测有没有与该记录关联的锁结构，发现 T2 还在等待获取锁，所以事务 T2 对应的锁结构的 `is_waiting` 属性值设置为 false，然后唤醒对应事务线程，T2 继续执行。

### 22.1.2 读-写 或 写-读 情况

在 读 - 写 或者 写 - 读 情况下会出现脏读、不可重复读、幻读现象

有两种方案解决这些现象：

- 读操作使用多版本并发控制（MVCC），写操作进行加锁

  MVCC 就是通过生成一个 Read View，通过 Read View 找到符合条件的版本。读操作使用 MVCC 可以读到旧版本，而写操作一定是修改的最新的版本，因此读写时互不影响的。

- 读、写都加锁

  如果一些业务场景不允许读取记录的旧版本，每次必须读取记录的最新版本，那就需要对其进行加锁操作。

使用 MVCC 性能比加锁高一些，我们愿意采用 MVCC，但是如果不允许，则必须加锁。

事务使用 MVCC 进行的读取操作称为一致性读，或者一致性无锁读，所有普通的 SELECT 语句在读已提交、可重复读隔离级别下都是一致性读。

### 22.1.3 锁定读

#### 共享锁和独占锁

锁可以分类为：

- 共享锁：S 锁，事务读取一条记录时，首先获得其共享锁
- 独占锁：X 锁，事务改动一条记录时，首先获得其独占锁

兼容关系：

| 兼容性 |  X 锁  |  S 锁  |
| :----: | :----: | :----: |
|  X 锁  | 不兼容 | 不兼容 |
|  S 锁  | 不兼容 |  兼容  |

#### 锁定读的语句

有时我们想在读取记录时就获取记录的 X 锁，从而禁止其他事务读写该记录，读取记录前就为该记录加锁的读取方式称为锁定度。

- 对读取的记录加 S 锁：

  ```sql
  select ... lock in share mode
  ```

  对读取操作加 S 锁

- 对读取的记录加 X 锁：

  ```sql
  select ... for update
  ```

  对读取操作加 X 锁

### 22.1.4 写操作

写操作无非是 Delete、Update、Insert 三种

- Delete：先在 B+ 树中定位到这条记录位置，然后获取这条记录的 X 锁，执行 delete mark。
- Update：分为三种情况：
  - 没有修改这条记录的主键，并且更新前后存储空间没有发生变化：先在 B+ 树找到记录位置，然后获取记录的 X 锁，然后原地修改。
  - 没有修改主键，但是更新前后存储空间变化：先在 B+ 树找到位置，然后加 X 锁，彻底删除该记录，插入新记录。
  - 修改主键：相当于原地先执行 Delete 再执行 Insert 操作。
- Insert：新插入的记录受隐式锁保护，不需要生成对应的锁结构。

> 特殊情况下 Insert 操作也会在内存中生成锁。

## 22.2 多粒度锁

由于锁分为表锁行锁，当表锁想上 S 锁时，需要确保没有记录上 X 锁，如果有，需要等到这个 X 锁撤销才能对表上 S 锁；当表锁想上 X 锁时，需要确保没有记录上其他锁，如果有需要等记录的锁全部撤销再上 X 锁。

难道这样做需要遍历吗？当然不能遍历，不让效率太低了。于是 InnoDB 设计者提出意向锁来解决：

- 意向共享锁：IS 锁：事务在某条记录上加 S 锁时，需要在表上加 IS 锁
- 意向独占锁：IX 锁：事务在某条记录上加 X 锁时，需要在表上加 IX 锁

IS 和 IX 仅仅是表级锁，他们的提出仅仅为了在之后加表级锁的 S 锁和 X 锁时可以快速判断表中记录是否上锁，避免遍历查看。

兼容性：

| 兼容性 | X      | IX     | S      | IS     |
| ------ | ------ | ------ | ------ | ------ |
| X      | 不兼容 | 不兼容 | 不兼容 | 不兼容 |
| IX     | 不兼容 | 兼容   | 不兼容 | 兼容   |
| S      | 不兼容 | 不兼容 | 兼容   | 兼容   |
| IS     | 不兼容 | 兼容   | 兼容   | 兼容   |

## 22.3 MySQL 中的行锁和表锁

### 22.3.1 其他存储引擎的锁

对于 MyISAM、MEMORY、MERGE 这些存储引擎来说只支持表级锁，且这些存储引擎不支持事务，所以加锁时一般都是针对当前会话来说。

### 22.3.2 InnoDB 存储引擎中的锁

InnoDB 既支持表锁也支持行锁，表锁粒度粗，占用资源少，但是性能差。行锁粒度低，可以实现更精准的并发控制，但是占用资源多。

#### InnDB 表锁

- 表级别的 S 锁、X 锁

  对某个表执行 Select、Insert、Delete、Update 语句时，InnoDB 引擎不会为这个表添加表级锁的。

  其实 InnoDB 的表锁很鸡肋，只在一些特殊情况下（例如系统崩溃恢复）才会使用。

- 表级别的 IS 锁、IX 锁

  对 InnoDB 存储引擎的表的某些记录加 S 锁前，需要现在表加一个 IS 锁，当对使用 InnoDB 引擎的表的某些记录加 X 锁前需要先在表上加一个 IX 锁。IX 和 IS 只是为了后续在加表级别的 S 锁和 X 锁时，判断表中是否有已经被加锁的记录，避免用遍历的方式来看表中有没有上锁的记录。

- 表级别的 Auto-INC 锁

  为某个列添加 `AUTO_INCREMENT` 属性时，之后插入记录系统会自动为它赋值。

  因为自增操作不是原子的，当多条记录并发插入时系统需要互斥维护自增值，因此需要在表级加一个 Auto-INC 锁，插入结束后，就可以释放这个锁。

#### InnoDB 中的行级锁

行级锁就是在一个记录上加锁，InnoDB 中的行锁有很多类型。

```sql
create table hero {
	number int,
	name varchar(100),
	country varchar(100),
	primary key (number)
} Engine=InnoDB charset=utf8;
```

向表中插几条数据：

```sql
insert into hero values 
	(1, 'l刘备', '蜀'),
	(3, 'z诸葛亮', '蜀'),
	(8, 'c曹操', '魏'),
	(15, 'x荀彧', '魏'),
	(20, 's孙权', '吴');
```

- Record Lock

  记录锁，仅仅将一条记录锁上，例如我们为 number 为 8 的记录上锁：

  ![image-20220609155740795](C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220609155740795.png)

  记录锁有 S 锁和 X 锁之分，兼容性和 S 锁 X 锁一样。

- Gap Lock

  MySQL 在可重复读隔离级别下可以很大程度上解决幻读现象，方案有两种：使用 MVCC、加锁。

  但是加锁方案有个问题，事务在一次执行读取操作，幻影记录如果不存在，我们无法给幻影记录上锁，这就需要 Gap Lock（间隙锁）

  <img src="C:\Users\HASEE\Desktop\读书笔记\MySQL是怎样运行的.assets\image-20220609160352157.png" alt="image-20220609160352157" style="zoom:50%;" />

  为 number 为8的记录加锁后，意味着不允许别的事务在 number 为 8 的记录前面的间隙插入新纪录，其实就是 number 列的值在区间（3,8）的新纪录是不允许立即插入的，例如另一个事务向插入一条 number 值为 4 的新纪录，需要定位到该条新纪录的小一条记录，也就是 number 值为 8 的记录，发现这条记录有一个 gap 锁，所以会阻塞插入操作。

- Next-Key Lock

  这种锁就是记录锁和间隙锁的结合，能锁住间隙的同时锁住记录。

- Insert Intention Lock

  插入意向锁，事务在插入一条记录时如果发现插入位置被加了 gap 锁，则需要等待，直到拥有 gap 锁的事务提交，事务在等待时也需要生成一个锁结构，表明有事务想在某个间隙中插入新记录，这个锁就是插入意向锁，事实上插入意向锁不会阻止别的事务继续获取该记录上任何类型的锁。

